{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0415 11:11:08.187197 15268 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(\n",
    "                re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "    dataset = tf.keras.utils.get_file(\n",
    "        fname=\"aclImdb.tar.gz\",\n",
    "        origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "        extract=True)\n",
    "    print(dataset)\n",
    "    print(os.path.dirname(dataset))\n",
    "\n",
    "    train_df = load_dataset(\n",
    "        os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
    "    test_df = load_dataset(\n",
    "        os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangfabei\\.keras\\datasets\\aclImdb.tar.gz\n",
      "C:\\Users\\wangfabei\\.keras\\datasets\n"
     ]
    }
   ],
   "source": [
    "# Reduce logging output.\n",
    "train, test = download_and_load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "sentence     25000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "polarity     25000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "sentence     25000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "polarity     25000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          polarity\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(5000)\n",
    "test = test.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>For Urban Cowboy John Travolta plays one of th...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20208</th>\n",
       "      <td>Michael Jackson would have claimed a spot for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>I love Westerns. I could watch them all day. \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>William Powell is Philo Vance in \"The Kennel M...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9446</th>\n",
       "      <td>I thought it was an extremely clever film. I w...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>Band Camp was awful, The Naked Mile was a litt...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>I'm a Belgian and grew up in the sixties. Most...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>Tea Leoni plays Nora Wilde, a serious photogra...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>A movie you start watching as a late night cab...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>It is no wonder this movie won 4 prices, it is...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment  polarity\n",
       "23021  For Urban Cowboy John Travolta plays one of th...         7         1\n",
       "20208  Michael Jackson would have claimed a spot for ...         4         0\n",
       "4553   I love Westerns. I could watch them all day. \"...         1         0\n",
       "1509   William Powell is Philo Vance in \"The Kennel M...         7         1\n",
       "9446   I thought it was an extremely clever film. I w...         9         1\n",
       "2297   Band Camp was awful, The Naked Mile was a litt...         3         0\n",
       "6707   I'm a Belgian and grew up in the sixties. Most...         9         1\n",
       "10785  Tea Leoni plays Nora Wilde, a serious photogra...         8         1\n",
       "8098   A movie you start watching as a late night cab...         8         1\n",
       "7567   It is no wonder this movie won 4 prices, it is...        10         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_InputExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\",\n",
    "                                        as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([\n",
    "                tokenization_info[\"vocab_file\"],\n",
    "                tokenization_info[\"do_lower_case\"]\n",
    "            ])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file,\n",
    "                                           do_lower_case=do_lower_case),vocab_file,do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 14:06:47.934486 15268 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "tokenizer,vocab_file ,do_lower_case= create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'bert',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_file\n",
    "do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('[PAD]', 0),\n",
       "             ('[unused0]', 1),\n",
       "             ('[unused1]', 2),\n",
       "             ('[unused2]', 3),\n",
       "             ('[unused3]', 4),\n",
       "             ('[unused4]', 5),\n",
       "             ('[unused5]', 6),\n",
       "             ('[unused6]', 7),\n",
       "             ('[unused7]', 8),\n",
       "             ('[unused8]', 9),\n",
       "             ('[unused9]', 10),\n",
       "             ('[unused10]', 11),\n",
       "             ('[unused11]', 12),\n",
       "             ('[unused12]', 13),\n",
       "             ('[unused13]', 14),\n",
       "             ('[unused14]', 15),\n",
       "             ('[unused15]', 16),\n",
       "             ('[unused16]', 17),\n",
       "             ('[unused17]', 18),\n",
       "             ('[unused18]', 19),\n",
       "             ('[unused19]', 20),\n",
       "             ('[unused20]', 21),\n",
       "             ('[unused21]', 22),\n",
       "             ('[unused22]', 23),\n",
       "             ('[unused23]', 24),\n",
       "             ('[unused24]', 25),\n",
       "             ('[unused25]', 26),\n",
       "             ('[unused26]', 27),\n",
       "             ('[unused27]', 28),\n",
       "             ('[unused28]', 29),\n",
       "             ('[unused29]', 30),\n",
       "             ('[unused30]', 31),\n",
       "             ('[unused31]', 32),\n",
       "             ('[unused32]', 33),\n",
       "             ('[unused33]', 34),\n",
       "             ('[unused34]', 35),\n",
       "             ('[unused35]', 36),\n",
       "             ('[unused36]', 37),\n",
       "             ('[unused37]', 38),\n",
       "             ('[unused38]', 39),\n",
       "             ('[unused39]', 40),\n",
       "             ('[unused40]', 41),\n",
       "             ('[unused41]', 42),\n",
       "             ('[unused42]', 43),\n",
       "             ('[unused43]', 44),\n",
       "             ('[unused44]', 45),\n",
       "             ('[unused45]', 46),\n",
       "             ('[unused46]', 47),\n",
       "             ('[unused47]', 48),\n",
       "             ('[unused48]', 49),\n",
       "             ('[unused49]', 50),\n",
       "             ('[unused50]', 51),\n",
       "             ('[unused51]', 52),\n",
       "             ('[unused52]', 53),\n",
       "             ('[unused53]', 54),\n",
       "             ('[unused54]', 55),\n",
       "             ('[unused55]', 56),\n",
       "             ('[unused56]', 57),\n",
       "             ('[unused57]', 58),\n",
       "             ('[unused58]', 59),\n",
       "             ('[unused59]', 60),\n",
       "             ('[unused60]', 61),\n",
       "             ('[unused61]', 62),\n",
       "             ('[unused62]', 63),\n",
       "             ('[unused63]', 64),\n",
       "             ('[unused64]', 65),\n",
       "             ('[unused65]', 66),\n",
       "             ('[unused66]', 67),\n",
       "             ('[unused67]', 68),\n",
       "             ('[unused68]', 69),\n",
       "             ('[unused69]', 70),\n",
       "             ('[unused70]', 71),\n",
       "             ('[unused71]', 72),\n",
       "             ('[unused72]', 73),\n",
       "             ('[unused73]', 74),\n",
       "             ('[unused74]', 75),\n",
       "             ('[unused75]', 76),\n",
       "             ('[unused76]', 77),\n",
       "             ('[unused77]', 78),\n",
       "             ('[unused78]', 79),\n",
       "             ('[unused79]', 80),\n",
       "             ('[unused80]', 81),\n",
       "             ('[unused81]', 82),\n",
       "             ('[unused82]', 83),\n",
       "             ('[unused83]', 84),\n",
       "             ('[unused84]', 85),\n",
       "             ('[unused85]', 86),\n",
       "             ('[unused86]', 87),\n",
       "             ('[unused87]', 88),\n",
       "             ('[unused88]', 89),\n",
       "             ('[unused89]', 90),\n",
       "             ('[unused90]', 91),\n",
       "             ('[unused91]', 92),\n",
       "             ('[unused92]', 93),\n",
       "             ('[unused93]', 94),\n",
       "             ('[unused94]', 95),\n",
       "             ('[unused95]', 96),\n",
       "             ('[unused96]', 97),\n",
       "             ('[unused97]', 98),\n",
       "             ('[unused98]', 99),\n",
       "             ('[UNK]', 100),\n",
       "             ('[CLS]', 101),\n",
       "             ('[SEP]', 102),\n",
       "             ('[MASK]', 103),\n",
       "             ('[unused99]', 104),\n",
       "             ('[unused100]', 105),\n",
       "             ('[unused101]', 106),\n",
       "             ('[unused102]', 107),\n",
       "             ('[unused103]', 108),\n",
       "             ('[unused104]', 109),\n",
       "             ('[unused105]', 110),\n",
       "             ('[unused106]', 111),\n",
       "             ('[unused107]', 112),\n",
       "             ('[unused108]', 113),\n",
       "             ('[unused109]', 114),\n",
       "             ('[unused110]', 115),\n",
       "             ('[unused111]', 116),\n",
       "             ('[unused112]', 117),\n",
       "             ('[unused113]', 118),\n",
       "             ('[unused114]', 119),\n",
       "             ('[unused115]', 120),\n",
       "             ('[unused116]', 121),\n",
       "             ('[unused117]', 122),\n",
       "             ('[unused118]', 123),\n",
       "             ('[unused119]', 124),\n",
       "             ('[unused120]', 125),\n",
       "             ('[unused121]', 126),\n",
       "             ('[unused122]', 127),\n",
       "             ('[unused123]', 128),\n",
       "             ('[unused124]', 129),\n",
       "             ('[unused125]', 130),\n",
       "             ('[unused126]', 131),\n",
       "             ('[unused127]', 132),\n",
       "             ('[unused128]', 133),\n",
       "             ('[unused129]', 134),\n",
       "             ('[unused130]', 135),\n",
       "             ('[unused131]', 136),\n",
       "             ('[unused132]', 137),\n",
       "             ('[unused133]', 138),\n",
       "             ('[unused134]', 139),\n",
       "             ('[unused135]', 140),\n",
       "             ('[unused136]', 141),\n",
       "             ('[unused137]', 142),\n",
       "             ('[unused138]', 143),\n",
       "             ('[unused139]', 144),\n",
       "             ('[unused140]', 145),\n",
       "             ('[unused141]', 146),\n",
       "             ('[unused142]', 147),\n",
       "             ('[unused143]', 148),\n",
       "             ('[unused144]', 149),\n",
       "             ('[unused145]', 150),\n",
       "             ('[unused146]', 151),\n",
       "             ('[unused147]', 152),\n",
       "             ('[unused148]', 153),\n",
       "             ('[unused149]', 154),\n",
       "             ('[unused150]', 155),\n",
       "             ('[unused151]', 156),\n",
       "             ('[unused152]', 157),\n",
       "             ('[unused153]', 158),\n",
       "             ('[unused154]', 159),\n",
       "             ('[unused155]', 160),\n",
       "             ('[unused156]', 161),\n",
       "             ('[unused157]', 162),\n",
       "             ('[unused158]', 163),\n",
       "             ('[unused159]', 164),\n",
       "             ('[unused160]', 165),\n",
       "             ('[unused161]', 166),\n",
       "             ('[unused162]', 167),\n",
       "             ('[unused163]', 168),\n",
       "             ('[unused164]', 169),\n",
       "             ('[unused165]', 170),\n",
       "             ('[unused166]', 171),\n",
       "             ('[unused167]', 172),\n",
       "             ('[unused168]', 173),\n",
       "             ('[unused169]', 174),\n",
       "             ('[unused170]', 175),\n",
       "             ('[unused171]', 176),\n",
       "             ('[unused172]', 177),\n",
       "             ('[unused173]', 178),\n",
       "             ('[unused174]', 179),\n",
       "             ('[unused175]', 180),\n",
       "             ('[unused176]', 181),\n",
       "             ('[unused177]', 182),\n",
       "             ('[unused178]', 183),\n",
       "             ('[unused179]', 184),\n",
       "             ('[unused180]', 185),\n",
       "             ('[unused181]', 186),\n",
       "             ('[unused182]', 187),\n",
       "             ('[unused183]', 188),\n",
       "             ('[unused184]', 189),\n",
       "             ('[unused185]', 190),\n",
       "             ('[unused186]', 191),\n",
       "             ('[unused187]', 192),\n",
       "             ('[unused188]', 193),\n",
       "             ('[unused189]', 194),\n",
       "             ('[unused190]', 195),\n",
       "             ('[unused191]', 196),\n",
       "             ('[unused192]', 197),\n",
       "             ('[unused193]', 198),\n",
       "             ('[unused194]', 199),\n",
       "             ('[unused195]', 200),\n",
       "             ('[unused196]', 201),\n",
       "             ('[unused197]', 202),\n",
       "             ('[unused198]', 203),\n",
       "             ('[unused199]', 204),\n",
       "             ('[unused200]', 205),\n",
       "             ('[unused201]', 206),\n",
       "             ('[unused202]', 207),\n",
       "             ('[unused203]', 208),\n",
       "             ('[unused204]', 209),\n",
       "             ('[unused205]', 210),\n",
       "             ('[unused206]', 211),\n",
       "             ('[unused207]', 212),\n",
       "             ('[unused208]', 213),\n",
       "             ('[unused209]', 214),\n",
       "             ('[unused210]', 215),\n",
       "             ('[unused211]', 216),\n",
       "             ('[unused212]', 217),\n",
       "             ('[unused213]', 218),\n",
       "             ('[unused214]', 219),\n",
       "             ('[unused215]', 220),\n",
       "             ('[unused216]', 221),\n",
       "             ('[unused217]', 222),\n",
       "             ('[unused218]', 223),\n",
       "             ('[unused219]', 224),\n",
       "             ('[unused220]', 225),\n",
       "             ('[unused221]', 226),\n",
       "             ('[unused222]', 227),\n",
       "             ('[unused223]', 228),\n",
       "             ('[unused224]', 229),\n",
       "             ('[unused225]', 230),\n",
       "             ('[unused226]', 231),\n",
       "             ('[unused227]', 232),\n",
       "             ('[unused228]', 233),\n",
       "             ('[unused229]', 234),\n",
       "             ('[unused230]', 235),\n",
       "             ('[unused231]', 236),\n",
       "             ('[unused232]', 237),\n",
       "             ('[unused233]', 238),\n",
       "             ('[unused234]', 239),\n",
       "             ('[unused235]', 240),\n",
       "             ('[unused236]', 241),\n",
       "             ('[unused237]', 242),\n",
       "             ('[unused238]', 243),\n",
       "             ('[unused239]', 244),\n",
       "             ('[unused240]', 245),\n",
       "             ('[unused241]', 246),\n",
       "             ('[unused242]', 247),\n",
       "             ('[unused243]', 248),\n",
       "             ('[unused244]', 249),\n",
       "             ('[unused245]', 250),\n",
       "             ('[unused246]', 251),\n",
       "             ('[unused247]', 252),\n",
       "             ('[unused248]', 253),\n",
       "             ('[unused249]', 254),\n",
       "             ('[unused250]', 255),\n",
       "             ('[unused251]', 256),\n",
       "             ('[unused252]', 257),\n",
       "             ('[unused253]', 258),\n",
       "             ('[unused254]', 259),\n",
       "             ('[unused255]', 260),\n",
       "             ('[unused256]', 261),\n",
       "             ('[unused257]', 262),\n",
       "             ('[unused258]', 263),\n",
       "             ('[unused259]', 264),\n",
       "             ('[unused260]', 265),\n",
       "             ('[unused261]', 266),\n",
       "             ('[unused262]', 267),\n",
       "             ('[unused263]', 268),\n",
       "             ('[unused264]', 269),\n",
       "             ('[unused265]', 270),\n",
       "             ('[unused266]', 271),\n",
       "             ('[unused267]', 272),\n",
       "             ('[unused268]', 273),\n",
       "             ('[unused269]', 274),\n",
       "             ('[unused270]', 275),\n",
       "             ('[unused271]', 276),\n",
       "             ('[unused272]', 277),\n",
       "             ('[unused273]', 278),\n",
       "             ('[unused274]', 279),\n",
       "             ('[unused275]', 280),\n",
       "             ('[unused276]', 281),\n",
       "             ('[unused277]', 282),\n",
       "             ('[unused278]', 283),\n",
       "             ('[unused279]', 284),\n",
       "             ('[unused280]', 285),\n",
       "             ('[unused281]', 286),\n",
       "             ('[unused282]', 287),\n",
       "             ('[unused283]', 288),\n",
       "             ('[unused284]', 289),\n",
       "             ('[unused285]', 290),\n",
       "             ('[unused286]', 291),\n",
       "             ('[unused287]', 292),\n",
       "             ('[unused288]', 293),\n",
       "             ('[unused289]', 294),\n",
       "             ('[unused290]', 295),\n",
       "             ('[unused291]', 296),\n",
       "             ('[unused292]', 297),\n",
       "             ('[unused293]', 298),\n",
       "             ('[unused294]', 299),\n",
       "             ('[unused295]', 300),\n",
       "             ('[unused296]', 301),\n",
       "             ('[unused297]', 302),\n",
       "             ('[unused298]', 303),\n",
       "             ('[unused299]', 304),\n",
       "             ('[unused300]', 305),\n",
       "             ('[unused301]', 306),\n",
       "             ('[unused302]', 307),\n",
       "             ('[unused303]', 308),\n",
       "             ('[unused304]', 309),\n",
       "             ('[unused305]', 310),\n",
       "             ('[unused306]', 311),\n",
       "             ('[unused307]', 312),\n",
       "             ('[unused308]', 313),\n",
       "             ('[unused309]', 314),\n",
       "             ('[unused310]', 315),\n",
       "             ('[unused311]', 316),\n",
       "             ('[unused312]', 317),\n",
       "             ('[unused313]', 318),\n",
       "             ('[unused314]', 319),\n",
       "             ('[unused315]', 320),\n",
       "             ('[unused316]', 321),\n",
       "             ('[unused317]', 322),\n",
       "             ('[unused318]', 323),\n",
       "             ('[unused319]', 324),\n",
       "             ('[unused320]', 325),\n",
       "             ('[unused321]', 326),\n",
       "             ('[unused322]', 327),\n",
       "             ('[unused323]', 328),\n",
       "             ('[unused324]', 329),\n",
       "             ('[unused325]', 330),\n",
       "             ('[unused326]', 331),\n",
       "             ('[unused327]', 332),\n",
       "             ('[unused328]', 333),\n",
       "             ('[unused329]', 334),\n",
       "             ('[unused330]', 335),\n",
       "             ('[unused331]', 336),\n",
       "             ('[unused332]', 337),\n",
       "             ('[unused333]', 338),\n",
       "             ('[unused334]', 339),\n",
       "             ('[unused335]', 340),\n",
       "             ('[unused336]', 341),\n",
       "             ('[unused337]', 342),\n",
       "             ('[unused338]', 343),\n",
       "             ('[unused339]', 344),\n",
       "             ('[unused340]', 345),\n",
       "             ('[unused341]', 346),\n",
       "             ('[unused342]', 347),\n",
       "             ('[unused343]', 348),\n",
       "             ('[unused344]', 349),\n",
       "             ('[unused345]', 350),\n",
       "             ('[unused346]', 351),\n",
       "             ('[unused347]', 352),\n",
       "             ('[unused348]', 353),\n",
       "             ('[unused349]', 354),\n",
       "             ('[unused350]', 355),\n",
       "             ('[unused351]', 356),\n",
       "             ('[unused352]', 357),\n",
       "             ('[unused353]', 358),\n",
       "             ('[unused354]', 359),\n",
       "             ('[unused355]', 360),\n",
       "             ('[unused356]', 361),\n",
       "             ('[unused357]', 362),\n",
       "             ('[unused358]', 363),\n",
       "             ('[unused359]', 364),\n",
       "             ('[unused360]', 365),\n",
       "             ('[unused361]', 366),\n",
       "             ('[unused362]', 367),\n",
       "             ('[unused363]', 368),\n",
       "             ('[unused364]', 369),\n",
       "             ('[unused365]', 370),\n",
       "             ('[unused366]', 371),\n",
       "             ('[unused367]', 372),\n",
       "             ('[unused368]', 373),\n",
       "             ('[unused369]', 374),\n",
       "             ('[unused370]', 375),\n",
       "             ('[unused371]', 376),\n",
       "             ('[unused372]', 377),\n",
       "             ('[unused373]', 378),\n",
       "             ('[unused374]', 379),\n",
       "             ('[unused375]', 380),\n",
       "             ('[unused376]', 381),\n",
       "             ('[unused377]', 382),\n",
       "             ('[unused378]', 383),\n",
       "             ('[unused379]', 384),\n",
       "             ('[unused380]', 385),\n",
       "             ('[unused381]', 386),\n",
       "             ('[unused382]', 387),\n",
       "             ('[unused383]', 388),\n",
       "             ('[unused384]', 389),\n",
       "             ('[unused385]', 390),\n",
       "             ('[unused386]', 391),\n",
       "             ('[unused387]', 392),\n",
       "             ('[unused388]', 393),\n",
       "             ('[unused389]', 394),\n",
       "             ('[unused390]', 395),\n",
       "             ('[unused391]', 396),\n",
       "             ('[unused392]', 397),\n",
       "             ('[unused393]', 398),\n",
       "             ('[unused394]', 399),\n",
       "             ('[unused395]', 400),\n",
       "             ('[unused396]', 401),\n",
       "             ('[unused397]', 402),\n",
       "             ('[unused398]', 403),\n",
       "             ('[unused399]', 404),\n",
       "             ('[unused400]', 405),\n",
       "             ('[unused401]', 406),\n",
       "             ('[unused402]', 407),\n",
       "             ('[unused403]', 408),\n",
       "             ('[unused404]', 409),\n",
       "             ('[unused405]', 410),\n",
       "             ('[unused406]', 411),\n",
       "             ('[unused407]', 412),\n",
       "             ('[unused408]', 413),\n",
       "             ('[unused409]', 414),\n",
       "             ('[unused410]', 415),\n",
       "             ('[unused411]', 416),\n",
       "             ('[unused412]', 417),\n",
       "             ('[unused413]', 418),\n",
       "             ('[unused414]', 419),\n",
       "             ('[unused415]', 420),\n",
       "             ('[unused416]', 421),\n",
       "             ('[unused417]', 422),\n",
       "             ('[unused418]', 423),\n",
       "             ('[unused419]', 424),\n",
       "             ('[unused420]', 425),\n",
       "             ('[unused421]', 426),\n",
       "             ('[unused422]', 427),\n",
       "             ('[unused423]', 428),\n",
       "             ('[unused424]', 429),\n",
       "             ('[unused425]', 430),\n",
       "             ('[unused426]', 431),\n",
       "             ('[unused427]', 432),\n",
       "             ('[unused428]', 433),\n",
       "             ('[unused429]', 434),\n",
       "             ('[unused430]', 435),\n",
       "             ('[unused431]', 436),\n",
       "             ('[unused432]', 437),\n",
       "             ('[unused433]', 438),\n",
       "             ('[unused434]', 439),\n",
       "             ('[unused435]', 440),\n",
       "             ('[unused436]', 441),\n",
       "             ('[unused437]', 442),\n",
       "             ('[unused438]', 443),\n",
       "             ('[unused439]', 444),\n",
       "             ('[unused440]', 445),\n",
       "             ('[unused441]', 446),\n",
       "             ('[unused442]', 447),\n",
       "             ('[unused443]', 448),\n",
       "             ('[unused444]', 449),\n",
       "             ('[unused445]', 450),\n",
       "             ('[unused446]', 451),\n",
       "             ('[unused447]', 452),\n",
       "             ('[unused448]', 453),\n",
       "             ('[unused449]', 454),\n",
       "             ('[unused450]', 455),\n",
       "             ('[unused451]', 456),\n",
       "             ('[unused452]', 457),\n",
       "             ('[unused453]', 458),\n",
       "             ('[unused454]', 459),\n",
       "             ('[unused455]', 460),\n",
       "             ('[unused456]', 461),\n",
       "             ('[unused457]', 462),\n",
       "             ('[unused458]', 463),\n",
       "             ('[unused459]', 464),\n",
       "             ('[unused460]', 465),\n",
       "             ('[unused461]', 466),\n",
       "             ('[unused462]', 467),\n",
       "             ('[unused463]', 468),\n",
       "             ('[unused464]', 469),\n",
       "             ('[unused465]', 470),\n",
       "             ('[unused466]', 471),\n",
       "             ('[unused467]', 472),\n",
       "             ('[unused468]', 473),\n",
       "             ('[unused469]', 474),\n",
       "             ('[unused470]', 475),\n",
       "             ('[unused471]', 476),\n",
       "             ('[unused472]', 477),\n",
       "             ('[unused473]', 478),\n",
       "             ('[unused474]', 479),\n",
       "             ('[unused475]', 480),\n",
       "             ('[unused476]', 481),\n",
       "             ('[unused477]', 482),\n",
       "             ('[unused478]', 483),\n",
       "             ('[unused479]', 484),\n",
       "             ('[unused480]', 485),\n",
       "             ('[unused481]', 486),\n",
       "             ('[unused482]', 487),\n",
       "             ('[unused483]', 488),\n",
       "             ('[unused484]', 489),\n",
       "             ('[unused485]', 490),\n",
       "             ('[unused486]', 491),\n",
       "             ('[unused487]', 492),\n",
       "             ('[unused488]', 493),\n",
       "             ('[unused489]', 494),\n",
       "             ('[unused490]', 495),\n",
       "             ('[unused491]', 496),\n",
       "             ('[unused492]', 497),\n",
       "             ('[unused493]', 498),\n",
       "             ('[unused494]', 499),\n",
       "             ('[unused495]', 500),\n",
       "             ('[unused496]', 501),\n",
       "             ('[unused497]', 502),\n",
       "             ('[unused498]', 503),\n",
       "             ('[unused499]', 504),\n",
       "             ('[unused500]', 505),\n",
       "             ('[unused501]', 506),\n",
       "             ('[unused502]', 507),\n",
       "             ('[unused503]', 508),\n",
       "             ('[unused504]', 509),\n",
       "             ('[unused505]', 510),\n",
       "             ('[unused506]', 511),\n",
       "             ('[unused507]', 512),\n",
       "             ('[unused508]', 513),\n",
       "             ('[unused509]', 514),\n",
       "             ('[unused510]', 515),\n",
       "             ('[unused511]', 516),\n",
       "             ('[unused512]', 517),\n",
       "             ('[unused513]', 518),\n",
       "             ('[unused514]', 519),\n",
       "             ('[unused515]', 520),\n",
       "             ('[unused516]', 521),\n",
       "             ('[unused517]', 522),\n",
       "             ('[unused518]', 523),\n",
       "             ('[unused519]', 524),\n",
       "             ('[unused520]', 525),\n",
       "             ('[unused521]', 526),\n",
       "             ('[unused522]', 527),\n",
       "             ('[unused523]', 528),\n",
       "             ('[unused524]', 529),\n",
       "             ('[unused525]', 530),\n",
       "             ('[unused526]', 531),\n",
       "             ('[unused527]', 532),\n",
       "             ('[unused528]', 533),\n",
       "             ('[unused529]', 534),\n",
       "             ('[unused530]', 535),\n",
       "             ('[unused531]', 536),\n",
       "             ('[unused532]', 537),\n",
       "             ('[unused533]', 538),\n",
       "             ('[unused534]', 539),\n",
       "             ('[unused535]', 540),\n",
       "             ('[unused536]', 541),\n",
       "             ('[unused537]', 542),\n",
       "             ('[unused538]', 543),\n",
       "             ('[unused539]', 544),\n",
       "             ('[unused540]', 545),\n",
       "             ('[unused541]', 546),\n",
       "             ('[unused542]', 547),\n",
       "             ('[unused543]', 548),\n",
       "             ('[unused544]', 549),\n",
       "             ('[unused545]', 550),\n",
       "             ('[unused546]', 551),\n",
       "             ('[unused547]', 552),\n",
       "             ('[unused548]', 553),\n",
       "             ('[unused549]', 554),\n",
       "             ('[unused550]', 555),\n",
       "             ('[unused551]', 556),\n",
       "             ('[unused552]', 557),\n",
       "             ('[unused553]', 558),\n",
       "             ('[unused554]', 559),\n",
       "             ('[unused555]', 560),\n",
       "             ('[unused556]', 561),\n",
       "             ('[unused557]', 562),\n",
       "             ('[unused558]', 563),\n",
       "             ('[unused559]', 564),\n",
       "             ('[unused560]', 565),\n",
       "             ('[unused561]', 566),\n",
       "             ('[unused562]', 567),\n",
       "             ('[unused563]', 568),\n",
       "             ('[unused564]', 569),\n",
       "             ('[unused565]', 570),\n",
       "             ('[unused566]', 571),\n",
       "             ('[unused567]', 572),\n",
       "             ('[unused568]', 573),\n",
       "             ('[unused569]', 574),\n",
       "             ('[unused570]', 575),\n",
       "             ('[unused571]', 576),\n",
       "             ('[unused572]', 577),\n",
       "             ('[unused573]', 578),\n",
       "             ('[unused574]', 579),\n",
       "             ('[unused575]', 580),\n",
       "             ('[unused576]', 581),\n",
       "             ('[unused577]', 582),\n",
       "             ('[unused578]', 583),\n",
       "             ('[unused579]', 584),\n",
       "             ('[unused580]', 585),\n",
       "             ('[unused581]', 586),\n",
       "             ('[unused582]', 587),\n",
       "             ('[unused583]', 588),\n",
       "             ('[unused584]', 589),\n",
       "             ('[unused585]', 590),\n",
       "             ('[unused586]', 591),\n",
       "             ('[unused587]', 592),\n",
       "             ('[unused588]', 593),\n",
       "             ('[unused589]', 594),\n",
       "             ('[unused590]', 595),\n",
       "             ('[unused591]', 596),\n",
       "             ('[unused592]', 597),\n",
       "             ('[unused593]', 598),\n",
       "             ('[unused594]', 599),\n",
       "             ('[unused595]', 600),\n",
       "             ('[unused596]', 601),\n",
       "             ('[unused597]', 602),\n",
       "             ('[unused598]', 603),\n",
       "             ('[unused599]', 604),\n",
       "             ('[unused600]', 605),\n",
       "             ('[unused601]', 606),\n",
       "             ('[unused602]', 607),\n",
       "             ('[unused603]', 608),\n",
       "             ('[unused604]', 609),\n",
       "             ('[unused605]', 610),\n",
       "             ('[unused606]', 611),\n",
       "             ('[unused607]', 612),\n",
       "             ('[unused608]', 613),\n",
       "             ('[unused609]', 614),\n",
       "             ('[unused610]', 615),\n",
       "             ('[unused611]', 616),\n",
       "             ('[unused612]', 617),\n",
       "             ('[unused613]', 618),\n",
       "             ('[unused614]', 619),\n",
       "             ('[unused615]', 620),\n",
       "             ('[unused616]', 621),\n",
       "             ('[unused617]', 622),\n",
       "             ('[unused618]', 623),\n",
       "             ('[unused619]', 624),\n",
       "             ('[unused620]', 625),\n",
       "             ('[unused621]', 626),\n",
       "             ('[unused622]', 627),\n",
       "             ('[unused623]', 628),\n",
       "             ('[unused624]', 629),\n",
       "             ('[unused625]', 630),\n",
       "             ('[unused626]', 631),\n",
       "             ('[unused627]', 632),\n",
       "             ('[unused628]', 633),\n",
       "             ('[unused629]', 634),\n",
       "             ('[unused630]', 635),\n",
       "             ('[unused631]', 636),\n",
       "             ('[unused632]', 637),\n",
       "             ('[unused633]', 638),\n",
       "             ('[unused634]', 639),\n",
       "             ('[unused635]', 640),\n",
       "             ('[unused636]', 641),\n",
       "             ('[unused637]', 642),\n",
       "             ('[unused638]', 643),\n",
       "             ('[unused639]', 644),\n",
       "             ('[unused640]', 645),\n",
       "             ('[unused641]', 646),\n",
       "             ('[unused642]', 647),\n",
       "             ('[unused643]', 648),\n",
       "             ('[unused644]', 649),\n",
       "             ('[unused645]', 650),\n",
       "             ('[unused646]', 651),\n",
       "             ('[unused647]', 652),\n",
       "             ('[unused648]', 653),\n",
       "             ('[unused649]', 654),\n",
       "             ('[unused650]', 655),\n",
       "             ('[unused651]', 656),\n",
       "             ('[unused652]', 657),\n",
       "             ('[unused653]', 658),\n",
       "             ('[unused654]', 659),\n",
       "             ('[unused655]', 660),\n",
       "             ('[unused656]', 661),\n",
       "             ('[unused657]', 662),\n",
       "             ('[unused658]', 663),\n",
       "             ('[unused659]', 664),\n",
       "             ('[unused660]', 665),\n",
       "             ('[unused661]', 666),\n",
       "             ('[unused662]', 667),\n",
       "             ('[unused663]', 668),\n",
       "             ('[unused664]', 669),\n",
       "             ('[unused665]', 670),\n",
       "             ('[unused666]', 671),\n",
       "             ('[unused667]', 672),\n",
       "             ('[unused668]', 673),\n",
       "             ('[unused669]', 674),\n",
       "             ('[unused670]', 675),\n",
       "             ('[unused671]', 676),\n",
       "             ('[unused672]', 677),\n",
       "             ('[unused673]', 678),\n",
       "             ('[unused674]', 679),\n",
       "             ('[unused675]', 680),\n",
       "             ('[unused676]', 681),\n",
       "             ('[unused677]', 682),\n",
       "             ('[unused678]', 683),\n",
       "             ('[unused679]', 684),\n",
       "             ('[unused680]', 685),\n",
       "             ('[unused681]', 686),\n",
       "             ('[unused682]', 687),\n",
       "             ('[unused683]', 688),\n",
       "             ('[unused684]', 689),\n",
       "             ('[unused685]', 690),\n",
       "             ('[unused686]', 691),\n",
       "             ('[unused687]', 692),\n",
       "             ('[unused688]', 693),\n",
       "             ('[unused689]', 694),\n",
       "             ('[unused690]', 695),\n",
       "             ('[unused691]', 696),\n",
       "             ('[unused692]', 697),\n",
       "             ('[unused693]', 698),\n",
       "             ('[unused694]', 699),\n",
       "             ('[unused695]', 700),\n",
       "             ('[unused696]', 701),\n",
       "             ('[unused697]', 702),\n",
       "             ('[unused698]', 703),\n",
       "             ('[unused699]', 704),\n",
       "             ('[unused700]', 705),\n",
       "             ('[unused701]', 706),\n",
       "             ('[unused702]', 707),\n",
       "             ('[unused703]', 708),\n",
       "             ('[unused704]', 709),\n",
       "             ('[unused705]', 710),\n",
       "             ('[unused706]', 711),\n",
       "             ('[unused707]', 712),\n",
       "             ('[unused708]', 713),\n",
       "             ('[unused709]', 714),\n",
       "             ('[unused710]', 715),\n",
       "             ('[unused711]', 716),\n",
       "             ('[unused712]', 717),\n",
       "             ('[unused713]', 718),\n",
       "             ('[unused714]', 719),\n",
       "             ('[unused715]', 720),\n",
       "             ('[unused716]', 721),\n",
       "             ('[unused717]', 722),\n",
       "             ('[unused718]', 723),\n",
       "             ('[unused719]', 724),\n",
       "             ('[unused720]', 725),\n",
       "             ('[unused721]', 726),\n",
       "             ('[unused722]', 727),\n",
       "             ('[unused723]', 728),\n",
       "             ('[unused724]', 729),\n",
       "             ('[unused725]', 730),\n",
       "             ('[unused726]', 731),\n",
       "             ('[unused727]', 732),\n",
       "             ('[unused728]', 733),\n",
       "             ('[unused729]', 734),\n",
       "             ('[unused730]', 735),\n",
       "             ('[unused731]', 736),\n",
       "             ('[unused732]', 737),\n",
       "             ('[unused733]', 738),\n",
       "             ('[unused734]', 739),\n",
       "             ('[unused735]', 740),\n",
       "             ('[unused736]', 741),\n",
       "             ('[unused737]', 742),\n",
       "             ('[unused738]', 743),\n",
       "             ('[unused739]', 744),\n",
       "             ('[unused740]', 745),\n",
       "             ('[unused741]', 746),\n",
       "             ('[unused742]', 747),\n",
       "             ('[unused743]', 748),\n",
       "             ('[unused744]', 749),\n",
       "             ('[unused745]', 750),\n",
       "             ('[unused746]', 751),\n",
       "             ('[unused747]', 752),\n",
       "             ('[unused748]', 753),\n",
       "             ('[unused749]', 754),\n",
       "             ('[unused750]', 755),\n",
       "             ('[unused751]', 756),\n",
       "             ('[unused752]', 757),\n",
       "             ('[unused753]', 758),\n",
       "             ('[unused754]', 759),\n",
       "             ('[unused755]', 760),\n",
       "             ('[unused756]', 761),\n",
       "             ('[unused757]', 762),\n",
       "             ('[unused758]', 763),\n",
       "             ('[unused759]', 764),\n",
       "             ('[unused760]', 765),\n",
       "             ('[unused761]', 766),\n",
       "             ('[unused762]', 767),\n",
       "             ('[unused763]', 768),\n",
       "             ('[unused764]', 769),\n",
       "             ('[unused765]', 770),\n",
       "             ('[unused766]', 771),\n",
       "             ('[unused767]', 772),\n",
       "             ('[unused768]', 773),\n",
       "             ('[unused769]', 774),\n",
       "             ('[unused770]', 775),\n",
       "             ('[unused771]', 776),\n",
       "             ('[unused772]', 777),\n",
       "             ('[unused773]', 778),\n",
       "             ('[unused774]', 779),\n",
       "             ('[unused775]', 780),\n",
       "             ('[unused776]', 781),\n",
       "             ('[unused777]', 782),\n",
       "             ('[unused778]', 783),\n",
       "             ('[unused779]', 784),\n",
       "             ('[unused780]', 785),\n",
       "             ('[unused781]', 786),\n",
       "             ('[unused782]', 787),\n",
       "             ('[unused783]', 788),\n",
       "             ('[unused784]', 789),\n",
       "             ('[unused785]', 790),\n",
       "             ('[unused786]', 791),\n",
       "             ('[unused787]', 792),\n",
       "             ('[unused788]', 793),\n",
       "             ('[unused789]', 794),\n",
       "             ('[unused790]', 795),\n",
       "             ('[unused791]', 796),\n",
       "             ('[unused792]', 797),\n",
       "             ('[unused793]', 798),\n",
       "             ('[unused794]', 799),\n",
       "             ('[unused795]', 800),\n",
       "             ('[unused796]', 801),\n",
       "             ('[unused797]', 802),\n",
       "             ('[unused798]', 803),\n",
       "             ('[unused799]', 804),\n",
       "             ('[unused800]', 805),\n",
       "             ('[unused801]', 806),\n",
       "             ('[unused802]', 807),\n",
       "             ('[unused803]', 808),\n",
       "             ('[unused804]', 809),\n",
       "             ('[unused805]', 810),\n",
       "             ('[unused806]', 811),\n",
       "             ('[unused807]', 812),\n",
       "             ('[unused808]', 813),\n",
       "             ('[unused809]', 814),\n",
       "             ('[unused810]', 815),\n",
       "             ('[unused811]', 816),\n",
       "             ('[unused812]', 817),\n",
       "             ('[unused813]', 818),\n",
       "             ('[unused814]', 819),\n",
       "             ('[unused815]', 820),\n",
       "             ('[unused816]', 821),\n",
       "             ('[unused817]', 822),\n",
       "             ('[unused818]', 823),\n",
       "             ('[unused819]', 824),\n",
       "             ('[unused820]', 825),\n",
       "             ('[unused821]', 826),\n",
       "             ('[unused822]', 827),\n",
       "             ('[unused823]', 828),\n",
       "             ('[unused824]', 829),\n",
       "             ('[unused825]', 830),\n",
       "             ('[unused826]', 831),\n",
       "             ('[unused827]', 832),\n",
       "             ('[unused828]', 833),\n",
       "             ('[unused829]', 834),\n",
       "             ('[unused830]', 835),\n",
       "             ('[unused831]', 836),\n",
       "             ('[unused832]', 837),\n",
       "             ('[unused833]', 838),\n",
       "             ('[unused834]', 839),\n",
       "             ('[unused835]', 840),\n",
       "             ('[unused836]', 841),\n",
       "             ('[unused837]', 842),\n",
       "             ('[unused838]', 843),\n",
       "             ('[unused839]', 844),\n",
       "             ('[unused840]', 845),\n",
       "             ('[unused841]', 846),\n",
       "             ('[unused842]', 847),\n",
       "             ('[unused843]', 848),\n",
       "             ('[unused844]', 849),\n",
       "             ('[unused845]', 850),\n",
       "             ('[unused846]', 851),\n",
       "             ('[unused847]', 852),\n",
       "             ('[unused848]', 853),\n",
       "             ('[unused849]', 854),\n",
       "             ('[unused850]', 855),\n",
       "             ('[unused851]', 856),\n",
       "             ('[unused852]', 857),\n",
       "             ('[unused853]', 858),\n",
       "             ('[unused854]', 859),\n",
       "             ('[unused855]', 860),\n",
       "             ('[unused856]', 861),\n",
       "             ('[unused857]', 862),\n",
       "             ('[unused858]', 863),\n",
       "             ('[unused859]', 864),\n",
       "             ('[unused860]', 865),\n",
       "             ('[unused861]', 866),\n",
       "             ('[unused862]', 867),\n",
       "             ('[unused863]', 868),\n",
       "             ('[unused864]', 869),\n",
       "             ('[unused865]', 870),\n",
       "             ('[unused866]', 871),\n",
       "             ('[unused867]', 872),\n",
       "             ('[unused868]', 873),\n",
       "             ('[unused869]', 874),\n",
       "             ('[unused870]', 875),\n",
       "             ('[unused871]', 876),\n",
       "             ('[unused872]', 877),\n",
       "             ('[unused873]', 878),\n",
       "             ('[unused874]', 879),\n",
       "             ('[unused875]', 880),\n",
       "             ('[unused876]', 881),\n",
       "             ('[unused877]', 882),\n",
       "             ('[unused878]', 883),\n",
       "             ('[unused879]', 884),\n",
       "             ('[unused880]', 885),\n",
       "             ('[unused881]', 886),\n",
       "             ('[unused882]', 887),\n",
       "             ('[unused883]', 888),\n",
       "             ('[unused884]', 889),\n",
       "             ('[unused885]', 890),\n",
       "             ('[unused886]', 891),\n",
       "             ('[unused887]', 892),\n",
       "             ('[unused888]', 893),\n",
       "             ('[unused889]', 894),\n",
       "             ('[unused890]', 895),\n",
       "             ('[unused891]', 896),\n",
       "             ('[unused892]', 897),\n",
       "             ('[unused893]', 898),\n",
       "             ('[unused894]', 899),\n",
       "             ('[unused895]', 900),\n",
       "             ('[unused896]', 901),\n",
       "             ('[unused897]', 902),\n",
       "             ('[unused898]', 903),\n",
       "             ('[unused899]', 904),\n",
       "             ('[unused900]', 905),\n",
       "             ('[unused901]', 906),\n",
       "             ('[unused902]', 907),\n",
       "             ('[unused903]', 908),\n",
       "             ('[unused904]', 909),\n",
       "             ('[unused905]', 910),\n",
       "             ('[unused906]', 911),\n",
       "             ('[unused907]', 912),\n",
       "             ('[unused908]', 913),\n",
       "             ('[unused909]', 914),\n",
       "             ('[unused910]', 915),\n",
       "             ('[unused911]', 916),\n",
       "             ('[unused912]', 917),\n",
       "             ('[unused913]', 918),\n",
       "             ('[unused914]', 919),\n",
       "             ('[unused915]', 920),\n",
       "             ('[unused916]', 921),\n",
       "             ('[unused917]', 922),\n",
       "             ('[unused918]', 923),\n",
       "             ('[unused919]', 924),\n",
       "             ('[unused920]', 925),\n",
       "             ('[unused921]', 926),\n",
       "             ('[unused922]', 927),\n",
       "             ('[unused923]', 928),\n",
       "             ('[unused924]', 929),\n",
       "             ('[unused925]', 930),\n",
       "             ('[unused926]', 931),\n",
       "             ('[unused927]', 932),\n",
       "             ('[unused928]', 933),\n",
       "             ('[unused929]', 934),\n",
       "             ('[unused930]', 935),\n",
       "             ('[unused931]', 936),\n",
       "             ('[unused932]', 937),\n",
       "             ('[unused933]', 938),\n",
       "             ('[unused934]', 939),\n",
       "             ('[unused935]', 940),\n",
       "             ('[unused936]', 941),\n",
       "             ('[unused937]', 942),\n",
       "             ('[unused938]', 943),\n",
       "             ('[unused939]', 944),\n",
       "             ('[unused940]', 945),\n",
       "             ('[unused941]', 946),\n",
       "             ('[unused942]', 947),\n",
       "             ('[unused943]', 948),\n",
       "             ('[unused944]', 949),\n",
       "             ('[unused945]', 950),\n",
       "             ('[unused946]', 951),\n",
       "             ('[unused947]', 952),\n",
       "             ('[unused948]', 953),\n",
       "             ('[unused949]', 954),\n",
       "             ('[unused950]', 955),\n",
       "             ('[unused951]', 956),\n",
       "             ('[unused952]', 957),\n",
       "             ('[unused953]', 958),\n",
       "             ('[unused954]', 959),\n",
       "             ('[unused955]', 960),\n",
       "             ('[unused956]', 961),\n",
       "             ('[unused957]', 962),\n",
       "             ('[unused958]', 963),\n",
       "             ('[unused959]', 964),\n",
       "             ('[unused960]', 965),\n",
       "             ('[unused961]', 966),\n",
       "             ('[unused962]', 967),\n",
       "             ('[unused963]', 968),\n",
       "             ('[unused964]', 969),\n",
       "             ('[unused965]', 970),\n",
       "             ('[unused966]', 971),\n",
       "             ('[unused967]', 972),\n",
       "             ('[unused968]', 973),\n",
       "             ('[unused969]', 974),\n",
       "             ('[unused970]', 975),\n",
       "             ('[unused971]', 976),\n",
       "             ('[unused972]', 977),\n",
       "             ('[unused973]', 978),\n",
       "             ('[unused974]', 979),\n",
       "             ('[unused975]', 980),\n",
       "             ('[unused976]', 981),\n",
       "             ('[unused977]', 982),\n",
       "             ('[unused978]', 983),\n",
       "             ('[unused979]', 984),\n",
       "             ('[unused980]', 985),\n",
       "             ('[unused981]', 986),\n",
       "             ('[unused982]', 987),\n",
       "             ('[unused983]', 988),\n",
       "             ('[unused984]', 989),\n",
       "             ('[unused985]', 990),\n",
       "             ('[unused986]', 991),\n",
       "             ('[unused987]', 992),\n",
       "             ('[unused988]', 993),\n",
       "             ('[unused989]', 994),\n",
       "             ('[unused990]', 995),\n",
       "             ('[unused991]', 996),\n",
       "             ('[unused992]', 997),\n",
       "             ('[unused993]', 998),\n",
       "             ('!', 999),\n",
       "             ...])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:23.992919 15268 run_classifier.py:774] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.000881 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.002881 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] for urban cowboy john tr ##av ##olt ##a plays one of the stronger alpha males ever portrayed on the big screen . he ' s a decent enough young kid who leaves his parent ' s homestead and strikes out for the big city of dallas where his uncle barry corbin has promised to find him work in the pet ##ro ##chemical industry . in 1980 that was beginning to boom and texas was definitely a growing place in the usa . < br / > < br / > tr ##av ##olt ##a does a good job in making we the audience care about his character who when you come right down to it is a sex ##ist pig . he meets and marries debra [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.003881 15268 run_classifier.py:464] tokens: [CLS] for urban cowboy john tr ##av ##olt ##a plays one of the stronger alpha males ever portrayed on the big screen . he ' s a decent enough young kid who leaves his parent ' s homestead and strikes out for the big city of dallas where his uncle barry corbin has promised to find him work in the pet ##ro ##chemical industry . in 1980 that was beginning to boom and texas was definitely a growing place in the usa . < br / > < br / > tr ##av ##olt ##a does a good job in making we the audience care about his character who when you come right down to it is a sex ##ist pig . he meets and marries debra [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2005 3923 11762 2198 19817 11431 27914 2050 3248 2028 1997 1996 6428 6541 3767 2412 6791 2006 1996 2502 3898 1012 2002 1005 1055 1037 11519 2438 2402 4845 2040 3727 2010 6687 1005 1055 14473 1998 9326 2041 2005 1996 2502 2103 1997 5759 2073 2010 4470 6287 24003 2038 5763 2000 2424 2032 2147 1999 1996 9004 3217 15869 3068 1012 1999 3150 2008 2001 2927 2000 8797 1998 3146 2001 5791 1037 3652 2173 1999 1996 3915 1012 1026 7987 1013 1028 1026 7987 1013 1028 19817 11431 27914 2050 2515 1037 2204 3105 1999 2437 2057 1996 4378 2729 2055 2010 2839 2040 2043 2017 2272 2157 2091 2000 2009 2003 1037 3348 2923 10369 1012 2002 6010 1998 19941 28762 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.004882 15268 run_classifier.py:465] input_ids: 101 2005 3923 11762 2198 19817 11431 27914 2050 3248 2028 1997 1996 6428 6541 3767 2412 6791 2006 1996 2502 3898 1012 2002 1005 1055 1037 11519 2438 2402 4845 2040 3727 2010 6687 1005 1055 14473 1998 9326 2041 2005 1996 2502 2103 1997 5759 2073 2010 4470 6287 24003 2038 5763 2000 2424 2032 2147 1999 1996 9004 3217 15869 3068 1012 1999 3150 2008 2001 2927 2000 8797 1998 3146 2001 5791 1037 3652 2173 1999 1996 3915 1012 1026 7987 1013 1028 1026 7987 1013 1028 19817 11431 27914 2050 2515 1037 2204 3105 1999 2437 2057 1996 4378 2729 2055 2010 2839 2040 2043 2017 2272 2157 2091 2000 2009 2003 1037 3348 2923 10369 1012 2002 6010 1998 19941 28762 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.005889 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.006881 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.008881 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.012885 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.014879 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] michael jackson would have claimed a spot for the top - billed character in the golden child , and because he loves kids . that didn ' t work ( and why should it ? ) , so instead we have eddie murphy out to save the world by rescuing \" kid mid ##as \" . i would strongly suggest all future script ##writer ##s to please thoroughly study the actor ' s ina ##ne dialogue in this qui ##rky fantasy - adventure - comedy that ' s a step closer to is ##hta ##r . whatever murphy says or does can be best liked , but don ' t get me wrong about his exquisite comical talent ; he doesn ' t belong in this [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.015878 15268 run_classifier.py:464] tokens: [CLS] michael jackson would have claimed a spot for the top - billed character in the golden child , and because he loves kids . that didn ' t work ( and why should it ? ) , so instead we have eddie murphy out to save the world by rescuing \" kid mid ##as \" . i would strongly suggest all future script ##writer ##s to please thoroughly study the actor ' s ina ##ne dialogue in this qui ##rky fantasy - adventure - comedy that ' s a step closer to is ##hta ##r . whatever murphy says or does can be best liked , but don ' t get me wrong about his exquisite comical talent ; he doesn ' t belong in this [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2745 4027 2052 2031 3555 1037 3962 2005 1996 2327 1011 14843 2839 1999 1996 3585 2775 1010 1998 2138 2002 7459 4268 1012 2008 2134 1005 1056 2147 1006 1998 2339 2323 2009 1029 1007 1010 2061 2612 2057 2031 5752 7104 2041 2000 3828 1996 2088 2011 23659 1000 4845 3054 3022 1000 1012 1045 2052 6118 6592 2035 2925 5896 15994 2015 2000 3531 12246 2817 1996 3364 1005 1055 27118 2638 7982 1999 2023 21864 15952 5913 1011 6172 1011 4038 2008 1005 1055 1037 3357 3553 2000 2003 22893 2099 1012 3649 7104 2758 2030 2515 2064 2022 2190 4669 1010 2021 2123 1005 1056 2131 2033 3308 2055 2010 19401 29257 5848 1025 2002 2987 1005 1056 7141 1999 2023 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.016878 15268 run_classifier.py:465] input_ids: 101 2745 4027 2052 2031 3555 1037 3962 2005 1996 2327 1011 14843 2839 1999 1996 3585 2775 1010 1998 2138 2002 7459 4268 1012 2008 2134 1005 1056 2147 1006 1998 2339 2323 2009 1029 1007 1010 2061 2612 2057 2031 5752 7104 2041 2000 3828 1996 2088 2011 23659 1000 4845 3054 3022 1000 1012 1045 2052 6118 6592 2035 2925 5896 15994 2015 2000 3531 12246 2817 1996 3364 1005 1055 27118 2638 7982 1999 2023 21864 15952 5913 1011 6172 1011 4038 2008 1005 1055 1037 3357 3553 2000 2003 22893 2099 1012 3649 7104 2758 2030 2515 2064 2022 2190 4669 1010 2021 2123 1005 1056 2131 2033 3308 2055 2010 19401 29257 5848 1025 2002 2987 1005 1056 7141 1999 2023 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.018895 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.019885 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.020892 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.026875 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.027875 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i love western ##s . i could watch them all day . \" the good , the bad , and the ugly \" is my all time favorite . i watched \" silver ##ado \" for probably the 8th time just the other day because it was being featured on cm ##t . however , this movie , shi ##loh falls is without a doubt the worst western i have ever watched . the acting was terrible all around . they explain nothing at the end of the mysterious compass looking thing . the only good part i can think of is the good - looking can ##tina girl . the very noticeable long pauses between the dial ##og seemed intentional just to make up time [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.029875 15268 run_classifier.py:464] tokens: [CLS] i love western ##s . i could watch them all day . \" the good , the bad , and the ugly \" is my all time favorite . i watched \" silver ##ado \" for probably the 8th time just the other day because it was being featured on cm ##t . however , this movie , shi ##loh falls is without a doubt the worst western i have ever watched . the acting was terrible all around . they explain nothing at the end of the mysterious compass looking thing . the only good part i can think of is the good - looking can ##tina girl . the very noticeable long pauses between the dial ##og seemed intentional just to make up time [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2293 2530 2015 1012 1045 2071 3422 2068 2035 2154 1012 1000 1996 2204 1010 1996 2919 1010 1998 1996 9200 1000 2003 2026 2035 2051 5440 1012 1045 3427 1000 3165 9365 1000 2005 2763 1996 5893 2051 2074 1996 2060 2154 2138 2009 2001 2108 2956 2006 4642 2102 1012 2174 1010 2023 3185 1010 11895 24729 4212 2003 2302 1037 4797 1996 5409 2530 1045 2031 2412 3427 1012 1996 3772 2001 6659 2035 2105 1012 2027 4863 2498 2012 1996 2203 1997 1996 8075 16681 2559 2518 1012 1996 2069 2204 2112 1045 2064 2228 1997 2003 1996 2204 1011 2559 2064 13770 2611 1012 1996 2200 17725 2146 19623 2090 1996 13764 8649 2790 21249 2074 2000 2191 2039 2051 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.030874 15268 run_classifier.py:465] input_ids: 101 1045 2293 2530 2015 1012 1045 2071 3422 2068 2035 2154 1012 1000 1996 2204 1010 1996 2919 1010 1998 1996 9200 1000 2003 2026 2035 2051 5440 1012 1045 3427 1000 3165 9365 1000 2005 2763 1996 5893 2051 2074 1996 2060 2154 2138 2009 2001 2108 2956 2006 4642 2102 1012 2174 1010 2023 3185 1010 11895 24729 4212 2003 2302 1037 4797 1996 5409 2530 1045 2031 2412 3427 1012 1996 3772 2001 6659 2035 2105 1012 2027 4863 2498 2012 1996 2203 1997 1996 8075 16681 2559 2518 1012 1996 2069 2204 2112 1045 2064 2228 1997 2003 1996 2204 1011 2559 2064 13770 2611 1012 1996 2200 17725 2146 19623 2090 1996 13764 8649 2790 21249 2074 2000 2191 2039 2051 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.031885 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.033876 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.034872 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.040876 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.041870 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] william powell is phil ##o vance in \" the ken ##nel murder case , \" a 1933 film also starring mary astor , paul ca ##vana ##gh , eugene palette , helen vin ##son and ralph morgan . a dog show in which phil ##o has entered his scottish terri ##er captain serves as the background for a locked room mystery with too many suspects . the mystery is very clever and the den ##oue ##ment both complicated and interesting . since the talk ##ies are still quite young , the camera work is a little static , but michael curt ##iz does a good job directing the action . < br / > < br / > the supporting cast is excellent ; the entire [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.043869 15268 run_classifier.py:464] tokens: [CLS] william powell is phil ##o vance in \" the ken ##nel murder case , \" a 1933 film also starring mary astor , paul ca ##vana ##gh , eugene palette , helen vin ##son and ralph morgan . a dog show in which phil ##o has entered his scottish terri ##er captain serves as the background for a locked room mystery with too many suspects . the mystery is very clever and the den ##oue ##ment both complicated and interesting . since the talk ##ies are still quite young , the camera work is a little static , but michael curt ##iz does a good job directing the action . < br / > < br / > the supporting cast is excellent ; the entire [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2520 8997 2003 6316 2080 16672 1999 1000 1996 6358 11877 4028 2553 1010 1000 1037 4537 2143 2036 4626 2984 25159 1010 2703 6187 27313 5603 1010 8207 27396 1010 6330 19354 3385 1998 6798 5253 1012 1037 3899 2265 1999 2029 6316 2080 2038 3133 2010 4104 26568 2121 2952 4240 2004 1996 4281 2005 1037 5299 2282 6547 2007 2205 2116 13172 1012 1996 6547 2003 2200 12266 1998 1996 7939 27872 3672 2119 8552 1998 5875 1012 2144 1996 2831 3111 2024 2145 3243 2402 1010 1996 4950 2147 2003 1037 2210 10763 1010 2021 2745 20099 10993 2515 1037 2204 3105 9855 1996 2895 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4637 3459 2003 6581 1025 1996 2972 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.044868 15268 run_classifier.py:465] input_ids: 101 2520 8997 2003 6316 2080 16672 1999 1000 1996 6358 11877 4028 2553 1010 1000 1037 4537 2143 2036 4626 2984 25159 1010 2703 6187 27313 5603 1010 8207 27396 1010 6330 19354 3385 1998 6798 5253 1012 1037 3899 2265 1999 2029 6316 2080 2038 3133 2010 4104 26568 2121 2952 4240 2004 1996 4281 2005 1037 5299 2282 6547 2007 2205 2116 13172 1012 1996 6547 2003 2200 12266 1998 1996 7939 27872 3672 2119 8552 1998 5875 1012 2144 1996 2831 3111 2024 2145 3243 2402 1010 1996 4950 2147 2003 1037 2210 10763 1010 2021 2745 20099 10993 2515 1037 2204 3105 9855 1996 2895 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 4637 3459 2003 6581 1025 1996 2972 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.045870 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.047874 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.048868 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.052868 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.053867 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i thought it was an extremely clever film . i was very pleased with it and truly couldn ' t ' ask for more . i actually own the film because i didn ' t return it to someone . . . which i should do , but i really want to keep it due to how much i enjoyed it . also , the fact i don ' t own too many foreign films and this is a first . now , i personally love finnish stuff so , that definitely added to how much i enjoyed it . but overall , its worth watching . however , if you ' re not into the whole trying to understand finnish or read sub ##titles bit [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.055865 15268 run_classifier.py:464] tokens: [CLS] i thought it was an extremely clever film . i was very pleased with it and truly couldn ' t ' ask for more . i actually own the film because i didn ' t return it to someone . . . which i should do , but i really want to keep it due to how much i enjoyed it . also , the fact i don ' t own too many foreign films and this is a first . now , i personally love finnish stuff so , that definitely added to how much i enjoyed it . but overall , its worth watching . however , if you ' re not into the whole trying to understand finnish or read sub ##titles bit [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2245 2009 2001 2019 5186 12266 2143 1012 1045 2001 2200 7537 2007 2009 1998 5621 2481 1005 1056 1005 3198 2005 2062 1012 1045 2941 2219 1996 2143 2138 1045 2134 1005 1056 2709 2009 2000 2619 1012 1012 1012 2029 1045 2323 2079 1010 2021 1045 2428 2215 2000 2562 2009 2349 2000 2129 2172 1045 5632 2009 1012 2036 1010 1996 2755 1045 2123 1005 1056 2219 2205 2116 3097 3152 1998 2023 2003 1037 2034 1012 2085 1010 1045 7714 2293 6983 4933 2061 1010 2008 5791 2794 2000 2129 2172 1045 5632 2009 1012 2021 3452 1010 2049 4276 3666 1012 2174 1010 2065 2017 1005 2128 2025 2046 1996 2878 2667 2000 3305 6983 2030 3191 4942 27430 2978 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.057871 15268 run_classifier.py:465] input_ids: 101 1045 2245 2009 2001 2019 5186 12266 2143 1012 1045 2001 2200 7537 2007 2009 1998 5621 2481 1005 1056 1005 3198 2005 2062 1012 1045 2941 2219 1996 2143 2138 1045 2134 1005 1056 2709 2009 2000 2619 1012 1012 1012 2029 1045 2323 2079 1010 2021 1045 2428 2215 2000 2562 2009 2349 2000 2129 2172 1045 5632 2009 1012 2036 1010 1996 2755 1045 2123 1005 1056 2219 2205 2116 3097 3152 1998 2023 2003 1037 2034 1012 2085 1010 1045 7714 2293 6983 4933 2061 1010 2008 5791 2794 2000 2129 2172 1045 5632 2009 1012 2021 3452 1010 2049 4276 3666 1012 2174 1010 2065 2017 1005 2128 2025 2046 1996 2878 2667 2000 3305 6983 2030 3191 4942 27430 2978 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.059866 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.060871 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:24.062874 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.954012 15268 run_classifier.py:774] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.957036 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.958005 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the daytime tv of films . seldom have i felt so little attachment to characters . seldom have i been made to cr ##inge by such dire dialogue . na ##use ##ous london thirty - something ##s min ##cing round lu ##rid bbc sets sp ##out ##ing pl ##ati ##tu ##din ##ous mu ##lch . avoid this film as if it were your grandmother ' s clung ##e . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.959007 15268 run_classifier.py:464] tokens: [CLS] the daytime tv of films . seldom have i felt so little attachment to characters . seldom have i been made to cr ##inge by such dire dialogue . na ##use ##ous london thirty - something ##s min ##cing round lu ##rid bbc sets sp ##out ##ing pl ##ati ##tu ##din ##ous mu ##lch . avoid this film as if it were your grandmother ' s clung ##e . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 12217 2694 1997 3152 1012 15839 2031 1045 2371 2061 2210 14449 2000 3494 1012 15839 2031 1045 2042 2081 2000 13675 23496 2011 2107 18704 7982 1012 6583 8557 3560 2414 4228 1011 2242 2015 8117 6129 2461 11320 14615 4035 4520 11867 5833 2075 20228 10450 8525 8718 3560 14163 29358 1012 4468 2023 2143 2004 2065 2009 2020 2115 7133 1005 1055 14752 2063 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.960014 15268 run_classifier.py:465] input_ids: 101 1996 12217 2694 1997 3152 1012 15839 2031 1045 2371 2061 2210 14449 2000 3494 1012 15839 2031 1045 2042 2081 2000 13675 23496 2011 2107 18704 7982 1012 6583 8557 3560 2414 4228 1011 2242 2015 8117 6129 2461 11320 14615 4035 4520 11867 5833 2075 20228 10450 8525 8718 3560 14163 29358 1012 4468 2023 2143 2004 2065 2009 2020 2115 7133 1005 1055 14752 2063 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.964004 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.965005 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.966006 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.970003 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.972005 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ed wood rides again . the fact that this movie was made should give any young < br / > < br / > aspiring film maker hope . any screenplay you might have thought of using to < br / > < br / > line a litter ##box or a bird ##ca ##ge should now not seem that bad . do not watch this movie unless you have a healthy st ##ash of ty ##len ##ol or ro ##laid ##s . watching this < br / > < br / > movie made me realize that bo ##a vs . python was not that bad after all . it probably would have been better to do this movie in clay ##mation as at least [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.973002 15268 run_classifier.py:464] tokens: [CLS] ed wood rides again . the fact that this movie was made should give any young < br / > < br / > aspiring film maker hope . any screenplay you might have thought of using to < br / > < br / > line a litter ##box or a bird ##ca ##ge should now not seem that bad . do not watch this movie unless you have a healthy st ##ash of ty ##len ##ol or ro ##laid ##s . watching this < br / > < br / > movie made me realize that bo ##a vs . python was not that bad after all . it probably would have been better to do this movie in clay ##mation as at least [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3968 3536 12271 2153 1012 1996 2755 2008 2023 3185 2001 2081 2323 2507 2151 2402 1026 7987 1013 1028 1026 7987 1013 1028 22344 2143 9338 3246 1012 2151 9000 2017 2453 2031 2245 1997 2478 2000 1026 7987 1013 1028 1026 7987 1013 1028 2240 1037 19070 8758 2030 1037 4743 3540 3351 2323 2085 2025 4025 2008 2919 1012 2079 2025 3422 2023 3185 4983 2017 2031 1037 7965 2358 11823 1997 5939 7770 4747 2030 20996 24393 2015 1012 3666 2023 1026 7987 1013 1028 1026 7987 1013 1028 3185 2081 2033 5382 2008 8945 2050 5443 1012 18750 2001 2025 2008 2919 2044 2035 1012 2009 2763 2052 2031 2042 2488 2000 2079 2023 3185 1999 5726 28649 2004 2012 2560 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.975009 15268 run_classifier.py:465] input_ids: 101 3968 3536 12271 2153 1012 1996 2755 2008 2023 3185 2001 2081 2323 2507 2151 2402 1026 7987 1013 1028 1026 7987 1013 1028 22344 2143 9338 3246 1012 2151 9000 2017 2453 2031 2245 1997 2478 2000 1026 7987 1013 1028 1026 7987 1013 1028 2240 1037 19070 8758 2030 1037 4743 3540 3351 2323 2085 2025 4025 2008 2919 1012 2079 2025 3422 2023 3185 4983 2017 2031 1037 7965 2358 11823 1997 5939 7770 4747 2030 20996 24393 2015 1012 3666 2023 1026 7987 1013 1028 1026 7987 1013 1028 3185 2081 2033 5382 2008 8945 2050 5443 1012 18750 2001 2025 2008 2919 2044 2035 1012 2009 2763 2052 2031 2042 2488 2000 2079 2023 3185 1999 5726 28649 2004 2012 2560 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.976003 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.978002 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.982003 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.990002 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.991002 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the last of the \" airport \" sequels . this has alain del ##on and george kennedy ( who was in all the airport movies ) as pilots ; david warner ( ! ! ! ) as the radio engineer ; susan blake ##ly as a news ##woman targeted for death ; robert wagner as a brilliant scientist ( stop laughing ! ) ; eddie albert as a president of the airlines ; char ##o in a dreadful \" comical \" bit ; john davidson as a news ##man ( love how his hair stays in place even after the plane turns upside down ! ) ; poor martha ray ##e is humiliated ; ci ##cel ##y tyson plays a mother who is flying a heart [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.992002 15268 run_classifier.py:464] tokens: [CLS] the last of the \" airport \" sequels . this has alain del ##on and george kennedy ( who was in all the airport movies ) as pilots ; david warner ( ! ! ! ) as the radio engineer ; susan blake ##ly as a news ##woman targeted for death ; robert wagner as a brilliant scientist ( stop laughing ! ) ; eddie albert as a president of the airlines ; char ##o in a dreadful \" comical \" bit ; john davidson as a news ##man ( love how his hair stays in place even after the plane turns upside down ! ) ; poor martha ray ##e is humiliated ; ci ##cel ##y tyson plays a mother who is flying a heart [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 2197 1997 1996 1000 3199 1000 25815 1012 2023 2038 15654 3972 2239 1998 2577 5817 1006 2040 2001 1999 2035 1996 3199 5691 1007 2004 8221 1025 2585 6654 1006 999 999 999 1007 2004 1996 2557 3992 1025 6294 6511 2135 2004 1037 2739 10169 9416 2005 2331 1025 2728 10304 2004 1037 8235 7155 1006 2644 5870 999 1007 1025 5752 4789 2004 1037 2343 1997 1996 7608 1025 25869 2080 1999 1037 21794 1000 29257 1000 2978 1025 2198 12017 2004 1037 2739 2386 1006 2293 2129 2010 2606 12237 1999 2173 2130 2044 1996 4946 4332 14961 2091 999 1007 1025 3532 9246 4097 2063 2003 26608 1025 25022 29109 2100 19356 3248 1037 2388 2040 2003 3909 1037 2540 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.993002 15268 run_classifier.py:465] input_ids: 101 1996 2197 1997 1996 1000 3199 1000 25815 1012 2023 2038 15654 3972 2239 1998 2577 5817 1006 2040 2001 1999 2035 1996 3199 5691 1007 2004 8221 1025 2585 6654 1006 999 999 999 1007 2004 1996 2557 3992 1025 6294 6511 2135 2004 1037 2739 10169 9416 2005 2331 1025 2728 10304 2004 1037 8235 7155 1006 2644 5870 999 1007 1025 5752 4789 2004 1037 2343 1997 1996 7608 1025 25869 2080 1999 1037 21794 1000 29257 1000 2978 1025 2198 12017 2004 1037 2739 2386 1006 2293 2129 2010 2606 12237 1999 2173 2130 2044 1996 4946 4332 14961 2091 999 1007 1025 3532 9246 4097 2063 2003 26608 1025 25022 29109 2100 19356 3248 1037 2388 2040 2003 3909 1037 2540 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.994000 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.996001 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:44.997001 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.002005 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.003999 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is a low budget , well acted little gem . alice , a small town massachusetts teenager , fed up with her existence , takes to the road to escape her mother who flip ##s burger ##s and her own job as a check out in a super market . she sets out for florida and to stay with her wealth ##ier high school friend who is a freshman at miami . after her car suspiciously breaks down on the thru ##way and she loses all her money , she ends up with a retired couple in an rv who also happen to be traveling to florida . . the couple , brilliant ##ly played by judith ivy and bill raymond are overly ho ##sp [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.004998 15268 run_classifier.py:464] tokens: [CLS] this is a low budget , well acted little gem . alice , a small town massachusetts teenager , fed up with her existence , takes to the road to escape her mother who flip ##s burger ##s and her own job as a check out in a super market . she sets out for florida and to stay with her wealth ##ier high school friend who is a freshman at miami . after her car suspiciously breaks down on the thru ##way and she loses all her money , she ends up with a retired couple in an rv who also happen to be traveling to florida . . the couple , brilliant ##ly played by judith ivy and bill raymond are overly ho ##sp [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 1037 2659 5166 1010 2092 6051 2210 17070 1012 5650 1010 1037 2235 2237 4404 10563 1010 7349 2039 2007 2014 4598 1010 3138 2000 1996 2346 2000 4019 2014 2388 2040 11238 2015 15890 2015 1998 2014 2219 3105 2004 1037 4638 2041 1999 1037 3565 3006 1012 2016 4520 2041 2005 3516 1998 2000 2994 2007 2014 7177 3771 2152 2082 2767 2040 2003 1037 10452 2012 5631 1012 2044 2014 2482 21501 7807 2091 2006 1996 27046 4576 1998 2016 12386 2035 2014 2769 1010 2016 4515 2039 2007 1037 3394 3232 1999 2019 27634 2040 2036 4148 2000 2022 7118 2000 3516 1012 1012 1996 3232 1010 8235 2135 2209 2011 12924 7768 1998 3021 7638 2024 15241 7570 13102 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.005998 15268 run_classifier.py:465] input_ids: 101 2023 2003 1037 2659 5166 1010 2092 6051 2210 17070 1012 5650 1010 1037 2235 2237 4404 10563 1010 7349 2039 2007 2014 4598 1010 3138 2000 1996 2346 2000 4019 2014 2388 2040 11238 2015 15890 2015 1998 2014 2219 3105 2004 1037 4638 2041 1999 1037 3565 3006 1012 2016 4520 2041 2005 3516 1998 2000 2994 2007 2014 7177 3771 2152 2082 2767 2040 2003 1037 10452 2012 5631 1012 2044 2014 2482 21501 7807 2091 2006 1996 27046 4576 1998 2016 12386 2035 2014 2769 1010 2016 4515 2039 2007 1037 3394 3232 1999 2019 27634 2040 2036 4148 2000 2022 7118 2000 3516 1012 1012 1996 3232 1010 8235 2135 2209 2011 12924 7768 1998 3021 7638 2024 15241 7570 13102 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.007998 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.008996 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.009997 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.015994 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.017995 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] normally , i don ' t like chuck norris films . i appreciate his work as a martial artist , and his fight scenes are usually fairly well - choreographed . chuck is und ##enia ##bly one of the martial arts great ##s . so , in my local used bookstore , i found a film i hadn ' t seen before and took it home . < br / > < br / > while the acting in this movie was worse than most chu ##ch norris films , i was hoping to see at least one fight scene . i quickly began to realize that this wasn ' t a typical chu ##ch norris film ; rather it was a christian film , destined [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.019993 15268 run_classifier.py:464] tokens: [CLS] normally , i don ' t like chuck norris films . i appreciate his work as a martial artist , and his fight scenes are usually fairly well - choreographed . chuck is und ##enia ##bly one of the martial arts great ##s . so , in my local used bookstore , i found a film i hadn ' t seen before and took it home . < br / > < br / > while the acting in this movie was worse than most chu ##ch norris films , i was hoping to see at least one fight scene . i quickly began to realize that this wasn ' t a typical chu ##ch norris film ; rather it was a christian film , destined [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5373 1010 1045 2123 1005 1056 2066 8057 15466 3152 1012 1045 9120 2010 2147 2004 1037 7761 3063 1010 1998 2010 2954 5019 2024 2788 7199 2092 1011 23317 1012 8057 2003 6151 19825 6321 2028 1997 1996 7761 2840 2307 2015 1012 2061 1010 1999 2026 2334 2109 21785 1010 1045 2179 1037 2143 1045 2910 1005 1056 2464 2077 1998 2165 2009 2188 1012 1026 7987 1013 1028 1026 7987 1013 1028 2096 1996 3772 1999 2023 3185 2001 4788 2084 2087 14684 2818 15466 3152 1010 1045 2001 5327 2000 2156 2012 2560 2028 2954 3496 1012 1045 2855 2211 2000 5382 2008 2023 2347 1005 1056 1037 5171 14684 2818 15466 2143 1025 2738 2009 2001 1037 3017 2143 1010 16036 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.020993 15268 run_classifier.py:465] input_ids: 101 5373 1010 1045 2123 1005 1056 2066 8057 15466 3152 1012 1045 9120 2010 2147 2004 1037 7761 3063 1010 1998 2010 2954 5019 2024 2788 7199 2092 1011 23317 1012 8057 2003 6151 19825 6321 2028 1997 1996 7761 2840 2307 2015 1012 2061 1010 1999 2026 2334 2109 21785 1010 1045 2179 1037 2143 1045 2910 1005 1056 2464 2077 1998 2165 2009 2188 1012 1026 7987 1013 1028 1026 7987 1013 1028 2096 1996 3772 1999 2023 3185 2001 4788 2084 2087 14684 2818 15466 3152 1010 1045 2001 5327 2000 2156 2012 2560 2028 2954 3496 1012 1045 2855 2211 2000 5382 2008 2023 2347 1005 1056 1037 5171 14684 2818 15466 2143 1025 2738 2009 2001 1037 3017 2143 1010 16036 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.022994 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.024992 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 18:07:45.025992 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bert.run_classifier.InputFeatures at 0x250774979e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497710>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ab38>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f3f1940>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f76cb38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749af60>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f76cef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f76c518>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f3d9198>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741362e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a748>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf06d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faec88>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0898>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d630>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d0f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d320>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d780>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c9b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e405f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e405c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136128>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741364a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40320>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ca20>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0390>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1278>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0160>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c3c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a9e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749dc50>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749da20>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0780>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf02b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774977b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a400>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136588>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a5f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0748>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0198>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f18d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741363c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0470>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faef28>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae128>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d470>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a6a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1860>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae3c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cb70>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf06a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faee48>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d5c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faedd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497208>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae6d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faed68>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c198>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ab70>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cd30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aa20>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a278>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1780>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d2b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d6a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d9b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faeba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c940>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c6a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d710>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf07f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf02e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497278>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c1d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ad68>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0860>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf07b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf09e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ce10>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749dc18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cf60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d8d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c2b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0048>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0320>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0710>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d1d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0438>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774972e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136908>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a8d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749dc88>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741367b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x250789f1d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c080>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774979b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774978d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741360b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136748>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0828>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e404a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40978>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d080>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749dcc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cb00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d940>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cbe0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40588>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136518>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d860>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741369e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae208>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749d9e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c470>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136208>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf00f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0240>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c048>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497780>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf08d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0278>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507bcf0358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae438>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774973c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a390>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aa90>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c2e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c5c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ab00>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ae10>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ae80>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ccc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ce80>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae828>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae9e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774976d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c780>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae518>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cc50>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cfd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40080>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a710>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a4a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a358>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ca90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faea58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae2e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44748>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a2e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44400>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae358>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae7b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae4a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e484a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faec18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136898>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774977f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774992e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497748>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774975f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497860>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749cda0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e449b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749af28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae5f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40240>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a2b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faeeb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a898>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a5c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae668>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a240>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c8d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749c358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae048>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741366d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e408d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e487f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e445c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a1d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae748>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44780>,\n",
       " <bert.run_classifier.InputFeatures at 0x250741365f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074136cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faecf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499048>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a6d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a9b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e403c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e406a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a1d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497438>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774994a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774998d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074fae588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faeac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faef98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e482b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074faeb38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aa90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a6d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497898>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774970b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774991d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a5f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ada0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4af60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e440f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ac88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077497c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4af98>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749add8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4acc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e400f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e442b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e409e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e447f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e444e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e486d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ac88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e481d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749af98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e443c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a198>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a780>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749acf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a630>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a588>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749acc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e407f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e401d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e400b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aa20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e406d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e402e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e407b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e444a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a438>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aa58>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a128>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ad30>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ac50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a0f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d6d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e447b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e442e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e440b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d4a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d6a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a828>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e402b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d438>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774995c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dd30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a202b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a208>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a209b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4add8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4df98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dd68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d2e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dfd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dc50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aeb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e486a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499588>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774996d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a203c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a204a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ac18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ae48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4de80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e487b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a206d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ad30>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a7b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499400>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774993c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48898>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749abe0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ada0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a630>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774999b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e404e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40160>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ae48>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749afd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499128>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749ac18>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749a3c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e40400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e409b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e449e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e448d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44908>,\n",
       " <bert.run_classifier.InputFeatures at 0x2507749aef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e489b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48358>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774997b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e483c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e480b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e484e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774997f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774995f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44048>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774996a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48710>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774990f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d908>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774999e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e482e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e441d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e485c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e480f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e485f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a139e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d9e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e489e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4df28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d7b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a455f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4deb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e446d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e445f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20780>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774990b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499470>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774992b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x250774994e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25077499710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e488d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a456a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e44b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e446a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a205c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a136d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a130f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a132e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d3c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a451d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ae80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4de48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4db70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d1d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20be0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a6a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dcf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4db38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ac50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a208d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b6d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a450f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4acf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a8d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ab70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a457f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a109e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13a58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13b38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bc50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a137b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d630>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a668>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10f60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a139b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b240>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aa58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b0b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a209e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13e48>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a107b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4de10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20d68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a452b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a205f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d5f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4da90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d588>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a102e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e48780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a100b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13e10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d2b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d0f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d5c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d9b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bc88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bbe0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45a20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20d30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a2b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13c18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10ba8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20390>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a455c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4da20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dcc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45278>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ab00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a105f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a109b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a0f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13908>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a130b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13518>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13e80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a131d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13da0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4af28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4be80>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d978>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4afd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dda0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bf98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10860>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a104a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10208>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bd68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45a90>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a201d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a135c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45828>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45cc0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a200b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a457b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ae10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a101d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45eb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4ddd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dc88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aeb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dbe0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b080>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4da58>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a454e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13320>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bc18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13cf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13358>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4dc18>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a136a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b780>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4db00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bcf8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4ba20>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b4e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4aef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a138d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a456d8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f510b70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4df60>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d550>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a7b8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f510198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4be10>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4abe0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a940>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a9e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a5c0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a748>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a048>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4beb8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b4a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13c50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d8d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20f98>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bb38>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10128>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20438>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4d400>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20ef0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a133c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a134e0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b160>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a20898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45c88>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4def0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13ac8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a200f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4ad68>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10198>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a13f28>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a4a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a3c8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b7f0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bda0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f52ba58>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f52b5f8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4b710>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bd30>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a458d0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a106a0>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f510898>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4bb70>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a454a8>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f52bc50>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45fd0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45898>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f5102b0>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a2e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a470>,\n",
       " <bert.run_classifier.InputFeatures at 0x25074e4a400>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f510550>,\n",
       " <bert.run_classifier.InputFeatures at 0x2506f5109e8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a45dd8>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a10b00>,\n",
       " <bert.run_classifier.InputFeatures at 0x25078a4be48>,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
    "    bert_inputs = dict(input_ids=input_ids,\n",
    "                       input_mask=input_mask,\n",
    "                       segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs,\n",
    "                               signature=\"tokens\",\n",
    "                               as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels],\n",
    "                                  initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(\n",
    "            tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'input_ids': Shape TensorShape([Dimension(128)]) is incompatible with TensorShape([Dimension(None), Dimension(None)])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-04b49b1b51d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-552fbefa5450>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbert_module\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBERT_MODEL_HUB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbert_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbert_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbert_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[0;32m    243\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[0;32m    244\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[1;32m--> 245\u001b[1;33m                                                tags=self._tags))\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[1;32mE:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[1;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[1;32m--> 447\u001b[1;33m                                                        tensor_info_map)\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow_hub\\tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[1;34m(values, targets)\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[1;32m--> 150\u001b[1;33m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[0;32m    151\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow_hub\\tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[1;34m(value, target, error_prefix)\u001b[0m\n\u001b[0;32m    127\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     raise TypeError(\"%s: Shape %r is incompatible with %r\" %\n\u001b[1;32m--> 129\u001b[1;33m                     (error_prefix, tensor.get_shape(), target.get_shape()))\n\u001b[0m\u001b[0;32m    130\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert 'input_ids': Shape TensorShape([Dimension(128)]) is incompatible with TensorShape([Dimension(None), Dimension(None)])"
     ]
    }
   ],
   "source": [
    "t=create_model(True,train_features[0].input_ids,train_features[0].input_mask,train_features[0].segment_ids,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
