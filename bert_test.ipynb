{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(\n",
    "                re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "    dataset = tf.keras.utils.get_file(\n",
    "        fname=\"aclImdb.tar.gz\",\n",
    "        origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "        extract=True)\n",
    "    print(dataset)\n",
    "    print(os.path.dirname(dataset))\n",
    "\n",
    "    train_df = load_dataset(\n",
    "        os.path.join(os.path.dirname(dataset), \"aclImdb\", \"train\"))\n",
    "    test_df = load_dataset(\n",
    "        os.path.join(os.path.dirname(dataset), \"aclImdb\", \"test\"))\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangfabei\\.keras\\datasets\\aclImdb.tar.gz\n",
      "C:\\Users\\wangfabei\\.keras\\datasets\n"
     ]
    }
   ],
   "source": [
    "# Reduce logging output.\n",
    "train, test = download_and_load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "sentence     25000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "polarity     25000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "sentence     25000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "polarity     25000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          polarity\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(5000)\n",
    "test = test.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9392</th>\n",
       "      <td>This is one of the worst movies I've seen in a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15543</th>\n",
       "      <td>I gave this a four purely out of its historica...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>I have no idea why this flick is getting such ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17458</th>\n",
       "      <td>I just saw this film yesterday.&lt;br /&gt;&lt;br /&gt;My ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>I have seen the movie at the Viennale a few ye...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>I bought this from Blockbuster for 99p. The gu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>I remember watching this is its original airin...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14764</th>\n",
       "      <td>This picture reminds me of a Keneth More pictu...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22079</th>\n",
       "      <td>I wonder who, how and more importantly why the...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>As a Pagan, I must say this movie has little i...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment  polarity\n",
       "9392   This is one of the worst movies I've seen in a...         1         0\n",
       "15543  I gave this a four purely out of its historica...         4         0\n",
       "3720   I have no idea why this flick is getting such ...         8         1\n",
       "17458  I just saw this film yesterday.<br /><br />My ...         1         0\n",
       "4273   I have seen the movie at the Viennale a few ye...         9         1\n",
       "6291   I bought this from Blockbuster for 99p. The gu...         1         0\n",
       "24977  I remember watching this is its original airin...         9         1\n",
       "14764  This picture reminds me of a Keneth More pictu...         3         0\n",
       "22079  I wonder who, how and more importantly why the...         3         0\n",
       "3869   As a Pagan, I must say this movie has little i...         9         1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_InputExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\",\n",
    "                                        as_dict=True)\n",
    "        print(tokenization_info)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([\n",
    "                tokenization_info[\"vocab_file\"],\n",
    "                tokenization_info[\"do_lower_case\"]\n",
    "            ])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file,\n",
    "                                           do_lower_case=do_lower_case),vocab_file,do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:33.744045 15268 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do_lower_case': <tf.Tensor 'module_apply_tokenization_info/Const:0' shape=() dtype=bool>, 'vocab_file': <tf.Tensor 'module_apply_tokenization_info/vocab_file:0' shape=() dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "tokenizer,vocab_file ,do_lower_case= create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'bert',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_file\n",
    "do_lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab\n",
    "len(tokenizer.inv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.601163 15268 run_classifier.py:774] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.604164 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.606168 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is one of the worst movies i ' ve seen in a long time . the story was boring , the dialogue was at ##ro ##cious and the acting ham ##my . i ' m not sure if this movie was the result of a film school homework project , but it certainly played like one . it is not even particularly successful in its central con ##ce ##it of trying to appear as a single continuous take . the who ##oshi ##ng horizontal camera pan ##s are a cheap and uno ##ri ##ginal way of hiding cuts . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.608164 15268 run_classifier.py:464] tokens: [CLS] this is one of the worst movies i ' ve seen in a long time . the story was boring , the dialogue was at ##ro ##cious and the acting ham ##my . i ' m not sure if this movie was the result of a film school homework project , but it certainly played like one . it is not even particularly successful in its central con ##ce ##it of trying to appear as a single continuous take . the who ##oshi ##ng horizontal camera pan ##s are a cheap and uno ##ri ##ginal way of hiding cuts . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 2028 1997 1996 5409 5691 1045 1005 2310 2464 1999 1037 2146 2051 1012 1996 2466 2001 11771 1010 1996 7982 2001 2012 3217 18436 1998 1996 3772 10654 8029 1012 1045 1005 1049 2025 2469 2065 2023 3185 2001 1996 2765 1997 1037 2143 2082 19453 2622 1010 2021 2009 5121 2209 2066 2028 1012 2009 2003 2025 2130 3391 3144 1999 2049 2430 9530 3401 4183 1997 2667 2000 3711 2004 1037 2309 7142 2202 1012 1996 2040 24303 3070 9876 4950 6090 2015 2024 1037 10036 1998 27776 3089 24965 2126 1997 6318 7659 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.609164 15268 run_classifier.py:465] input_ids: 101 2023 2003 2028 1997 1996 5409 5691 1045 1005 2310 2464 1999 1037 2146 2051 1012 1996 2466 2001 11771 1010 1996 7982 2001 2012 3217 18436 1998 1996 3772 10654 8029 1012 1045 1005 1049 2025 2469 2065 2023 3185 2001 1996 2765 1997 1037 2143 2082 19453 2622 1010 2021 2009 5121 2209 2066 2028 1012 2009 2003 2025 2130 3391 3144 1999 2049 2430 9530 3401 4183 1997 2667 2000 3711 2004 1037 2309 7142 2202 1012 1996 2040 24303 3070 9876 4950 6090 2015 2024 1037 10036 1998 27776 3089 24965 2126 1997 6318 7659 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.611163 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.614166 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.615164 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.619165 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.621165 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i gave this a four purely out of its historical context . it was considered lost for many years until it popped up out of the blue on showtime in the early nine ##ties . < br / > < br / > moe is the straight man and larry and curly act as a duo . spade cool ##ey has a couple of numbers . i guess it had something to do with working on a ranch . i ' m not quite sure because the plot was so minimal nothing really sticks in my memory . i vaguely remember it being a western musical comedy . even the st ##oo ##ge ' s seem to be going through the motions . overall there ' [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.622177 15268 run_classifier.py:464] tokens: [CLS] i gave this a four purely out of its historical context . it was considered lost for many years until it popped up out of the blue on showtime in the early nine ##ties . < br / > < br / > moe is the straight man and larry and curly act as a duo . spade cool ##ey has a couple of numbers . i guess it had something to do with working on a ranch . i ' m not quite sure because the plot was so minimal nothing really sticks in my memory . i vaguely remember it being a western musical comedy . even the st ##oo ##ge ' s seem to be going through the motions . overall there ' [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2435 2023 1037 2176 11850 2041 1997 2049 3439 6123 1012 2009 2001 2641 2439 2005 2116 2086 2127 2009 10538 2039 2041 1997 1996 2630 2006 23811 1999 1996 2220 3157 7368 1012 1026 7987 1013 1028 1026 7987 1013 1028 22078 2003 1996 3442 2158 1998 6554 1998 17546 2552 2004 1037 6829 1012 23288 4658 3240 2038 1037 3232 1997 3616 1012 1045 3984 2009 2018 2242 2000 2079 2007 2551 2006 1037 8086 1012 1045 1005 1049 2025 3243 2469 2138 1996 5436 2001 2061 10124 2498 2428 12668 1999 2026 3638 1012 1045 15221 3342 2009 2108 1037 2530 3315 4038 1012 2130 1996 2358 9541 3351 1005 1055 4025 2000 2022 2183 2083 1996 15323 1012 3452 2045 1005 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.624163 15268 run_classifier.py:465] input_ids: 101 1045 2435 2023 1037 2176 11850 2041 1997 2049 3439 6123 1012 2009 2001 2641 2439 2005 2116 2086 2127 2009 10538 2039 2041 1997 1996 2630 2006 23811 1999 1996 2220 3157 7368 1012 1026 7987 1013 1028 1026 7987 1013 1028 22078 2003 1996 3442 2158 1998 6554 1998 17546 2552 2004 1037 6829 1012 23288 4658 3240 2038 1037 3232 1997 3616 1012 1045 3984 2009 2018 2242 2000 2079 2007 2551 2006 1037 8086 1012 1045 1005 1049 2025 3243 2469 2138 1996 5436 2001 2061 10124 2498 2428 12668 1999 2026 3638 1012 1045 15221 3342 2009 2108 1037 2530 3315 4038 1012 2130 1996 2358 9541 3351 1005 1055 4025 2000 2022 2183 2083 1996 15323 1012 3452 2045 1005 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.626163 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.627164 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.629165 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.635179 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.637166 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i have no idea why this flick is getting such a bad rap by so many im ##db users ( some are saying it ' s his ' worst movie ever . ' what ? ? haven ' t any of you seen cradle 2 the grave ? ) my favorite criticism is that the plot is totally stupid , and just an excuse to hang all of the action sequences on . du ##h ! what the crap were you expecting from a jet li movie ? did you honestly believe that someone thought up the story , then just loaded it up with action ? of course not ! black mask is awesome , wall - to - wall action throughout nearly it ' [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.638164 15268 run_classifier.py:464] tokens: [CLS] i have no idea why this flick is getting such a bad rap by so many im ##db users ( some are saying it ' s his ' worst movie ever . ' what ? ? haven ' t any of you seen cradle 2 the grave ? ) my favorite criticism is that the plot is totally stupid , and just an excuse to hang all of the action sequences on . du ##h ! what the crap were you expecting from a jet li movie ? did you honestly believe that someone thought up the story , then just loaded it up with action ? of course not ! black mask is awesome , wall - to - wall action throughout nearly it ' [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2031 2053 2801 2339 2023 17312 2003 2893 2107 1037 2919 9680 2011 2061 2116 10047 18939 5198 1006 2070 2024 3038 2009 1005 1055 2010 1005 5409 3185 2412 1012 1005 2054 1029 1029 4033 1005 1056 2151 1997 2017 2464 18293 1016 1996 6542 1029 1007 2026 5440 6256 2003 2008 1996 5436 2003 6135 5236 1010 1998 2074 2019 8016 2000 6865 2035 1997 1996 2895 10071 2006 1012 4241 2232 999 2054 1996 10231 2020 2017 8074 2013 1037 6892 5622 3185 1029 2106 2017 9826 2903 2008 2619 2245 2039 1996 2466 1010 2059 2074 8209 2009 2039 2007 2895 1029 1997 2607 2025 999 2304 7308 2003 12476 1010 2813 1011 2000 1011 2813 2895 2802 3053 2009 1005 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.640166 15268 run_classifier.py:465] input_ids: 101 1045 2031 2053 2801 2339 2023 17312 2003 2893 2107 1037 2919 9680 2011 2061 2116 10047 18939 5198 1006 2070 2024 3038 2009 1005 1055 2010 1005 5409 3185 2412 1012 1005 2054 1029 1029 4033 1005 1056 2151 1997 2017 2464 18293 1016 1996 6542 1029 1007 2026 5440 6256 2003 2008 1996 5436 2003 6135 5236 1010 1998 2074 2019 8016 2000 6865 2035 1997 1996 2895 10071 2006 1012 4241 2232 999 2054 1996 10231 2020 2017 8074 2013 1037 6892 5622 3185 1029 2106 2017 9826 2903 2008 2619 2245 2039 1996 2466 1010 2059 2074 8209 2009 2039 2007 2895 1029 1997 2607 2025 999 2304 7308 2003 12476 1010 2813 1011 2000 1011 2813 2895 2802 3053 2009 1005 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.641164 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.642164 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.643164 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.650164 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.651170 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i just saw this film yesterday . < br / > < br / > my girlfriend wanted to see it only because of richard ge ##re . < br / > < br / > i feel i wasted my time and money and told my girlfriend it ' s the last time we go to see a film just because a certain actor / actress is in it . i hope she learned the lesson because i had trouble keeping her in her seat . as of me , since i paid already , i wanted to see the end at least , just in the hope something good would turn up , but i didn ' t hold my breath , and luckily [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.652163 15268 run_classifier.py:464] tokens: [CLS] i just saw this film yesterday . < br / > < br / > my girlfriend wanted to see it only because of richard ge ##re . < br / > < br / > i feel i wasted my time and money and told my girlfriend it ' s the last time we go to see a film just because a certain actor / actress is in it . i hope she learned the lesson because i had trouble keeping her in her seat . as of me , since i paid already , i wanted to see the end at least , just in the hope something good would turn up , but i didn ' t hold my breath , and luckily [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2074 2387 2023 2143 7483 1012 1026 7987 1013 1028 1026 7987 1013 1028 2026 6513 2359 2000 2156 2009 2069 2138 1997 2957 16216 2890 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2514 1045 13842 2026 2051 1998 2769 1998 2409 2026 6513 2009 1005 1055 1996 2197 2051 2057 2175 2000 2156 1037 2143 2074 2138 1037 3056 3364 1013 3883 2003 1999 2009 1012 1045 3246 2016 4342 1996 10800 2138 1045 2018 4390 4363 2014 1999 2014 2835 1012 2004 1997 2033 1010 2144 1045 3825 2525 1010 1045 2359 2000 2156 1996 2203 2012 2560 1010 2074 1999 1996 3246 2242 2204 2052 2735 2039 1010 2021 1045 2134 1005 1056 2907 2026 3052 1010 1998 15798 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.654165 15268 run_classifier.py:465] input_ids: 101 1045 2074 2387 2023 2143 7483 1012 1026 7987 1013 1028 1026 7987 1013 1028 2026 6513 2359 2000 2156 2009 2069 2138 1997 2957 16216 2890 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2514 1045 13842 2026 2051 1998 2769 1998 2409 2026 6513 2009 1005 1055 1996 2197 2051 2057 2175 2000 2156 1037 2143 2074 2138 1037 3056 3364 1013 3883 2003 1999 2009 1012 1045 3246 2016 4342 1996 10800 2138 1045 2018 4390 4363 2014 1999 2014 2835 1012 2004 1997 2033 1010 2144 1045 3825 2525 1010 1045 2359 2000 2156 1996 2203 2012 2560 1010 2074 1999 1996 3246 2242 2204 2052 2735 2039 1010 2021 1045 2134 1005 1056 2907 2026 3052 1010 1998 15798 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.655165 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.656164 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.657164 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.662163 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.665165 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i have seen the movie at the vienna ##le a few years ago , where the audiences liked it . i liked it as well , summer phoenix performance still haunt ##s me , that ##´s why i decided to write a comment . < br / > < br / > the story un ##fold ##s in london around 1900 , where a jewish girl decides to become an actress . she tries desperately to become one , but it isn ##´ ##t before a man treats her badly that she realizes on stage , that she has talent and that she connects with the audience and emerges as a stronger human being . < br / > < br / > there were certain [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.666165 15268 run_classifier.py:464] tokens: [CLS] i have seen the movie at the vienna ##le a few years ago , where the audiences liked it . i liked it as well , summer phoenix performance still haunt ##s me , that ##´s why i decided to write a comment . < br / > < br / > the story un ##fold ##s in london around 1900 , where a jewish girl decides to become an actress . she tries desperately to become one , but it isn ##´ ##t before a man treats her badly that she realizes on stage , that she has talent and that she connects with the audience and emerges as a stronger human being . < br / > < br / > there were certain [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2031 2464 1996 3185 2012 1996 6004 2571 1037 2261 2086 3283 1010 2073 1996 9501 4669 2009 1012 1045 4669 2009 2004 2092 1010 2621 6708 2836 2145 24542 2015 2033 1010 2008 21932 2339 1045 2787 2000 4339 1037 7615 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2466 4895 10371 2015 1999 2414 2105 5141 1010 2073 1037 3644 2611 7288 2000 2468 2019 3883 1012 2016 5363 9652 2000 2468 2028 1010 2021 2009 3475 29658 2102 2077 1037 2158 18452 2014 6649 2008 2016 10919 2006 2754 1010 2008 2016 2038 5848 1998 2008 2016 8539 2007 1996 4378 1998 19391 2004 1037 6428 2529 2108 1012 1026 7987 1013 1028 1026 7987 1013 1028 2045 2020 3056 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.668165 15268 run_classifier.py:465] input_ids: 101 1045 2031 2464 1996 3185 2012 1996 6004 2571 1037 2261 2086 3283 1010 2073 1996 9501 4669 2009 1012 1045 4669 2009 2004 2092 1010 2621 6708 2836 2145 24542 2015 2033 1010 2008 21932 2339 1045 2787 2000 4339 1037 7615 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2466 4895 10371 2015 1999 2414 2105 5141 1010 2073 1037 3644 2611 7288 2000 2468 2019 3883 1012 2016 5363 9652 2000 2468 2028 1010 2021 2009 3475 29658 2102 2077 1037 2158 18452 2014 6649 2008 2016 10919 2006 2754 1010 2008 2016 2038 5848 1998 2008 2016 8539 2007 1996 4378 1998 19391 2004 1037 6428 2529 2108 1012 1026 7987 1013 1028 1026 7987 1013 1028 2045 2020 3056 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.669164 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.671166 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:34.672164 15268 run_classifier.py:468] label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.130303 15268 run_classifier.py:774] Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.135339 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.138303 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] julie andrews satirical ##ly pro ##ds her own good ##y - two - shoes image in this over ##pro ##duced musical comedy - drama , but if she approaches her role with ap ##lom ##b , she ' s alone in doing so . blake edwards ' film about a woman who is both music - hall entertainer and german spy during w ##wi doesn ' t know what tone to aim for , and rock hudson has the thank ##less task of playing romantic second - fiddle . musicals had grown out of favor by 1970 , and elephant ##ine productions like \" star ! \" and this film really tar ##nished andrews ' reputation , leaving a lot of dead space in her catalogue [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.139304 15268 run_classifier.py:464] tokens: [CLS] julie andrews satirical ##ly pro ##ds her own good ##y - two - shoes image in this over ##pro ##duced musical comedy - drama , but if she approaches her role with ap ##lom ##b , she ' s alone in doing so . blake edwards ' film about a woman who is both music - hall entertainer and german spy during w ##wi doesn ' t know what tone to aim for , and rock hudson has the thank ##less task of playing romantic second - fiddle . musicals had grown out of favor by 1970 , and elephant ##ine productions like \" star ! \" and this film really tar ##nished andrews ' reputation , leaving a lot of dead space in her catalogue [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7628 9261 17251 2135 4013 5104 2014 2219 2204 2100 1011 2048 1011 6007 3746 1999 2023 2058 21572 28901 3315 4038 1011 3689 1010 2021 2065 2016 8107 2014 2535 2007 9706 21297 2497 1010 2016 1005 1055 2894 1999 2725 2061 1012 6511 7380 1005 2143 2055 1037 2450 2040 2003 2119 2189 1011 2534 21751 1998 2446 8645 2076 1059 9148 2987 1005 1056 2113 2054 4309 2000 6614 2005 1010 1998 2600 6842 2038 1996 4067 3238 4708 1997 2652 6298 2117 1011 15888 1012 20103 2018 4961 2041 1997 5684 2011 3359 1010 1998 10777 3170 5453 2066 1000 2732 999 1000 1998 2023 2143 2428 16985 28357 9261 1005 5891 1010 2975 1037 2843 1997 2757 2686 1999 2014 10161 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.143304 15268 run_classifier.py:465] input_ids: 101 7628 9261 17251 2135 4013 5104 2014 2219 2204 2100 1011 2048 1011 6007 3746 1999 2023 2058 21572 28901 3315 4038 1011 3689 1010 2021 2065 2016 8107 2014 2535 2007 9706 21297 2497 1010 2016 1005 1055 2894 1999 2725 2061 1012 6511 7380 1005 2143 2055 1037 2450 2040 2003 2119 2189 1011 2534 21751 1998 2446 8645 2076 1059 9148 2987 1005 1056 2113 2054 4309 2000 6614 2005 1010 1998 2600 6842 2038 1996 4067 3238 4708 1997 2652 6298 2117 1011 15888 1012 20103 2018 4961 2041 1997 5684 2011 3359 1010 1998 10777 3170 5453 2066 1000 2732 999 1000 1998 2023 2143 2428 16985 28357 9261 1005 5891 1010 2975 1037 2843 1997 2757 2686 1999 2014 10161 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.145304 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.149305 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.151304 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.158312 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.161306 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] \" heaven can wait \" is a crushing bore and a candy - coated , mis ##ogy ##nist lie . i can ' t imagine anyone but film students sitting through it today . don am ##eche is in almost every scene , and , while he has a mel ##li ##fl ##uous voice that no doubt contributed to his successful career in radio , he doesn ' t have the char ##ism ##a to carry this film . am ##eche plays henry , a woman ##izer . lu ##bit ##sch wants to make henry ' s sexual inc ##ont ##inen ##ce adorable and amusing , and so he directs am ##eche to play the part as bland ##ly as possible . the combination of am [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.163306 15268 run_classifier.py:464] tokens: [CLS] \" heaven can wait \" is a crushing bore and a candy - coated , mis ##ogy ##nist lie . i can ' t imagine anyone but film students sitting through it today . don am ##eche is in almost every scene , and , while he has a mel ##li ##fl ##uous voice that no doubt contributed to his successful career in radio , he doesn ' t have the char ##ism ##a to carry this film . am ##eche plays henry , a woman ##izer . lu ##bit ##sch wants to make henry ' s sexual inc ##ont ##inen ##ce adorable and amusing , and so he directs am ##eche to play the part as bland ##ly as possible . the combination of am [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1000 6014 2064 3524 1000 2003 1037 14527 8501 1998 1037 9485 1011 15026 1010 28616 15707 26942 4682 1012 1045 2064 1005 1056 5674 3087 2021 2143 2493 3564 2083 2009 2651 1012 2123 2572 27635 2003 1999 2471 2296 3496 1010 1998 1010 2096 2002 2038 1037 11463 3669 10258 8918 2376 2008 2053 4797 5201 2000 2010 3144 2476 1999 2557 1010 2002 2987 1005 1056 2031 1996 25869 2964 2050 2000 4287 2023 2143 1012 2572 27635 3248 2888 1010 1037 2450 17629 1012 11320 16313 11624 4122 2000 2191 2888 1005 1055 4424 4297 12162 21820 3401 23677 1998 19142 1010 1998 2061 2002 23303 2572 27635 2000 2377 1996 2112 2004 20857 2135 2004 2825 1012 1996 5257 1997 2572 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.165306 15268 run_classifier.py:465] input_ids: 101 1000 6014 2064 3524 1000 2003 1037 14527 8501 1998 1037 9485 1011 15026 1010 28616 15707 26942 4682 1012 1045 2064 1005 1056 5674 3087 2021 2143 2493 3564 2083 2009 2651 1012 2123 2572 27635 2003 1999 2471 2296 3496 1010 1998 1010 2096 2002 2038 1037 11463 3669 10258 8918 2376 2008 2053 4797 5201 2000 2010 3144 2476 1999 2557 1010 2002 2987 1005 1056 2031 1996 25869 2964 2050 2000 4287 2023 2143 1012 2572 27635 3248 2888 1010 1037 2450 17629 1012 11320 16313 11624 4122 2000 2191 2888 1005 1055 4424 4297 12162 21820 3401 23677 1998 19142 1010 1998 2061 2002 23303 2572 27635 2000 2377 1996 2112 2004 20857 2135 2004 2825 1012 1996 5257 1997 2572 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.167311 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.169312 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.170307 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.177306 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.179306 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] some people may remember ms . russell from films such as \" black widow \" , which had some appeal and critical acclaim . boy , she must have really needed a rent check when she signed on to do this dog . < br / > < br / > yes , there will be those who like the gr ##at ##uit ##ous violence and nu ##dity . but one must sit back and wonder , in retro ##sp ##ect , what possessed anyone to spend money and time to make this in the first place . i just saw this movie on one of the \" hbo ' s \" , and i can ' t believe they picked it up . < br [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.181310 15268 run_classifier.py:464] tokens: [CLS] some people may remember ms . russell from films such as \" black widow \" , which had some appeal and critical acclaim . boy , she must have really needed a rent check when she signed on to do this dog . < br / > < br / > yes , there will be those who like the gr ##at ##uit ##ous violence and nu ##dity . but one must sit back and wonder , in retro ##sp ##ect , what possessed anyone to spend money and time to make this in the first place . i just saw this movie on one of the \" hbo ' s \" , and i can ' t believe they picked it up . < br [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2070 2111 2089 3342 5796 1012 5735 2013 3152 2107 2004 1000 2304 7794 1000 1010 2029 2018 2070 5574 1998 4187 10761 1012 2879 1010 2016 2442 2031 2428 2734 1037 9278 4638 2043 2016 2772 2006 2000 2079 2023 3899 1012 1026 7987 1013 1028 1026 7987 1013 1028 2748 1010 2045 2097 2022 2216 2040 2066 1996 24665 4017 14663 3560 4808 1998 16371 25469 1012 2021 2028 2442 4133 2067 1998 4687 1010 1999 22307 13102 22471 1010 2054 8679 3087 2000 5247 2769 1998 2051 2000 2191 2023 1999 1996 2034 2173 1012 1045 2074 2387 2023 3185 2006 2028 1997 1996 1000 14633 1005 1055 1000 1010 1998 1045 2064 1005 1056 2903 2027 3856 2009 2039 1012 1026 7987 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.183310 15268 run_classifier.py:465] input_ids: 101 2070 2111 2089 3342 5796 1012 5735 2013 3152 2107 2004 1000 2304 7794 1000 1010 2029 2018 2070 5574 1998 4187 10761 1012 2879 1010 2016 2442 2031 2428 2734 1037 9278 4638 2043 2016 2772 2006 2000 2079 2023 3899 1012 1026 7987 1013 1028 1026 7987 1013 1028 2748 1010 2045 2097 2022 2216 2040 2066 1996 24665 4017 14663 3560 4808 1998 16371 25469 1012 2021 2028 2442 4133 2067 1998 4687 1010 1999 22307 13102 22471 1010 2054 8679 3087 2000 5247 2769 1998 2051 2000 2191 2023 1999 1996 2034 2173 1012 1045 2074 2387 2023 3185 2006 2028 1997 1996 1000 14633 1005 1055 1000 1010 1998 1045 2064 1005 1056 2903 2027 3856 2009 2039 1012 1026 7987 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.184304 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.187305 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.189305 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.207308 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.209305 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the most irritating thing about \" dies d ' ago ##st \" ( august days ) is not simply that nothing happens in this film but that director marc rec ##ha has the nerve to pretend that this film is some sort of homage to leftist catalan journalist ramon barn ##ils . unless mentioning barn ##ils ' name a few times constitutes an \" homage , \" this pre ##tens ##e is an utter fraud . you will learn virtually nothing about barn ##ils in this film nor about the spanish civil war ( 1936 - 1939 ) nor about the special role of cat ##al ##un ##ya in that war . you also will not learn about the collective punishment inflicted on the heroic catalan [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.211309 15268 run_classifier.py:464] tokens: [CLS] the most irritating thing about \" dies d ' ago ##st \" ( august days ) is not simply that nothing happens in this film but that director marc rec ##ha has the nerve to pretend that this film is some sort of homage to leftist catalan journalist ramon barn ##ils . unless mentioning barn ##ils ' name a few times constitutes an \" homage , \" this pre ##tens ##e is an utter fraud . you will learn virtually nothing about barn ##ils in this film nor about the spanish civil war ( 1936 - 1939 ) nor about the special role of cat ##al ##un ##ya in that war . you also will not learn about the collective punishment inflicted on the heroic catalan [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 2087 29348 2518 2055 1000 8289 1040 1005 3283 3367 1000 1006 2257 2420 1007 2003 2025 3432 2008 2498 6433 1999 2023 2143 2021 2008 2472 7871 28667 3270 2038 1996 9113 2000 9811 2008 2023 2143 2003 2070 4066 1997 14822 2000 24247 13973 4988 12716 8659 12146 1012 4983 18625 8659 12146 1005 2171 1037 2261 2335 17367 2019 1000 14822 1010 1000 2023 3653 25808 2063 2003 2019 14395 9861 1012 2017 2097 4553 8990 2498 2055 8659 12146 1999 2023 2143 4496 2055 1996 3009 2942 2162 1006 4266 1011 3912 1007 4496 2055 1996 2569 2535 1997 4937 2389 4609 3148 1999 2008 2162 1012 2017 2036 2097 2025 4553 2055 1996 7268 7750 17303 2006 1996 14779 13973 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.212306 15268 run_classifier.py:465] input_ids: 101 1996 2087 29348 2518 2055 1000 8289 1040 1005 3283 3367 1000 1006 2257 2420 1007 2003 2025 3432 2008 2498 6433 1999 2023 2143 2021 2008 2472 7871 28667 3270 2038 1996 9113 2000 9811 2008 2023 2143 2003 2070 4066 1997 14822 2000 24247 13973 4988 12716 8659 12146 1012 4983 18625 8659 12146 1005 2171 1037 2261 2335 17367 2019 1000 14822 1010 1000 2023 3653 25808 2063 2003 2019 14395 9861 1012 2017 2097 4553 8990 2498 2055 8659 12146 1999 2023 2143 4496 2055 1996 3009 2942 2162 1006 4266 1011 3912 1007 4496 2055 1996 2569 2535 1997 4937 2389 4609 3148 1999 2008 2162 1012 2017 2036 2097 2025 4553 2055 1996 7268 7750 17303 2006 1996 14779 13973 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.216315 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.219310 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.220306 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.226306 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.228305 15268 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] \" submerged \" is definitely not \" the worst movie ever \" . it does have its flaws , such as borrowed footage , crazy script and non - existent special effects ( these are the worst ) , but it also has some good points too . the acting is surprisingly good , there are lots of familiar faces whom you probably know if u ' re a b - movie fan like me . < br / > < br / > i was very glad to see brent huff playing one of the heroes , knowing him mostly for his 80 ' s action films , and i must admit , he is not a bad actor at all . fred williamson , [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.229305 15268 run_classifier.py:464] tokens: [CLS] \" submerged \" is definitely not \" the worst movie ever \" . it does have its flaws , such as borrowed footage , crazy script and non - existent special effects ( these are the worst ) , but it also has some good points too . the acting is surprisingly good , there are lots of familiar faces whom you probably know if u ' re a b - movie fan like me . < br / > < br / > i was very glad to see brent huff playing one of the heroes , knowing him mostly for his 80 ' s action films , and i must admit , he is not a bad actor at all . fred williamson , [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1000 13563 1000 2003 5791 2025 1000 1996 5409 3185 2412 1000 1012 2009 2515 2031 2049 21407 1010 2107 2004 11780 8333 1010 4689 5896 1998 2512 1011 25953 2569 3896 1006 2122 2024 1996 5409 1007 1010 2021 2009 2036 2038 2070 2204 2685 2205 1012 1996 3772 2003 10889 2204 1010 2045 2024 7167 1997 5220 5344 3183 2017 2763 2113 2065 1057 1005 2128 1037 1038 1011 3185 5470 2066 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2001 2200 5580 2000 2156 12895 21301 2652 2028 1997 1996 7348 1010 4209 2032 3262 2005 2010 3770 1005 1055 2895 3152 1010 1998 1045 2442 6449 1010 2002 2003 2025 1037 2919 3364 2012 2035 1012 5965 14333 1010 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.231310 15268 run_classifier.py:465] input_ids: 101 1000 13563 1000 2003 5791 2025 1000 1996 5409 3185 2412 1000 1012 2009 2515 2031 2049 21407 1010 2107 2004 11780 8333 1010 4689 5896 1998 2512 1011 25953 2569 3896 1006 2122 2024 1996 5409 1007 1010 2021 2009 2036 2038 2070 2204 2685 2205 1012 1996 3772 2003 10889 2204 1010 2045 2024 7167 1997 5220 5344 3183 2017 2763 2113 2065 1057 1005 2128 1037 1038 1011 3185 5470 2066 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1045 2001 2200 5580 2000 2156 12895 21301 2652 2028 1997 1996 7348 1010 4209 2032 3262 2005 2010 3770 1005 1055 2895 3152 1010 1998 1045 2442 6449 1010 2002 2003 2025 1037 2919 3364 2012 2035 1012 5965 14333 1010 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.233309 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.234304 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:44:56.237305 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2023, 2003, 2028, 1997, 1996, 5409, 5691, 1045, 1005, 2310, 2464, 1999, 1037, 2146, 2051, 1012, 1996, 2466, 2001, 11771, 1010, 1996, 7982, 2001, 2012, 3217, 18436, 1998, 1996, 3772, 10654, 8029, 1012, 1045, 1005, 1049, 2025, 2469, 2065, 2023, 3185, 2001, 1996, 2765, 1997, 1037, 2143, 2082, 19453, 2622, 1010, 2021, 2009, 5121, 2209, 2066, 2028, 1012, 2009, 2003, 2025, 2130, 3391, 3144, 1999, 2049, 2430, 9530, 3401, 4183, 1997, 2667, 2000, 3711, 2004, 1037, 2309, 7142, 2202, 1012, 1996, 2040, 24303, 3070, 9876, 4950, 6090, 2015, 2024, 1037, 10036, 1998, 27776, 3089, 24965, 2126, 1997, 6318, 7659, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_features[0].input_ids)\n",
    "print('--------')\n",
    "print(train_features[0].input_mask)\n",
    "print('--------')\n",
    "print(train_features[0].segment_ids)\n",
    "print('--------')\n",
    "print(train_features[0].label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
    "    bert_inputs = dict(input_ids=input_ids,\n",
    "                       input_mask=input_mask,\n",
    "                       segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs,\n",
    "                               signature=\"tokens\",\n",
    "                               as_dict=True)\n",
    "    print(\"bert_outputs\")\n",
    "    print(bert_outputs)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels],\n",
    "                                  initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(\n",
    "            tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            (loss, predicted_labels,\n",
    "             log_probs) = create_model(is_predicting, input_ids, input_mask,\n",
    "                                       segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss,\n",
    "                                                          learning_rate,\n",
    "                                                          num_train_steps,\n",
    "                                                          num_warmup_steps,\n",
    "                                                          use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics.\n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                f1_score = tf.contrib.metrics.f1_score(label_ids,\n",
    "                                                       predicted_labels)\n",
    "                auc = tf.metrics.auc(label_ids, predicted_labels)\n",
    "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(label_ids,\n",
    "                                                     predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids,\n",
    "                                                     predicted_labels)\n",
    "                false_pos = tf.metrics.false_positives(label_ids,\n",
    "                                                       predicted_labels)\n",
    "                false_neg = tf.metrics.false_negatives(label_ids,\n",
    "                                                       predicted_labels)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"f1_score\": f1_score,\n",
    "                    \"auc\": auc,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                  loss=loss,\n",
    "                                                  train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                                  loss=loss,\n",
    "                                                  eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels,\n",
    "             log_probs) = create_model(is_predicting, input_ids, input_mask,\n",
    "                                       segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "import os\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = r'F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR=curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'F:\\\\testDemo\\\\AI\\\\NER\\\\ChineseNER-based-BERT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025007F6B8D0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0417 10:45:17.957018 15268 estimator.py:201] Using config: {'_model_dir': 'F:\\\\testDemo\\\\AI\\\\NER\\\\ChineseNER-based-BERT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025007F6B8D0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:15.338690 15268 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:18.137732 15268 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-fc6d547eb7c7>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 19:34:18.260733 15268 deprecation.py:506] From <ipython-input-31-fc6d547eb7c7>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\training\\learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 19:34:18.298728 15268 deprecation.py:323] From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\training\\learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 19:34:18.372739 15268 deprecation.py:323] From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 19:34:26.062871 15268 deprecation.py:323] From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:35.775805 15268 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:35.779805 15268 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:40.039306 15268 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:47.399367 15268 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:47.669407 15268 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:34:57.581342 15268 basic_session_run_hooks.py:594] Saving checkpoints for 0 into F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.70957804, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 19:35:48.683395 15268 basic_session_run_hooks.py:249] loss = 0.70957804, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0417055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 20:15:46.448743 15268 basic_session_run_hooks.py:680] global_step/sec: 0.0417055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4229948, step = 101 (2397.769 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 20:15:46.452743 15268 basic_session_run_hooks.py:247] loss = 0.4229948, step = 101 (2397.769 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0423198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 20:55:09.411018 15268 basic_session_run_hooks.py:680] global_step/sec: 0.0423198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33431265, step = 201 (2362.961 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 20:55:09.414014 15268 basic_session_run_hooks.py:247] loss = 0.33431265, step = 201 (2362.961 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0433165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 21:33:38.001643 15268 basic_session_run_hooks.py:680] global_step/sec: 0.0433165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.059133593, step = 301 (2308.591 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 21:33:38.004645 15268 basic_session_run_hooks.py:247] loss = 0.059133593, step = 301 (2308.591 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0433236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:12:06.210760 15268 basic_session_run_hooks.py:680] global_step/sec: 0.0433236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.008503004, step = 401 (2308.209 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:12:06.214752 15268 basic_session_run_hooks.py:247] loss = 0.008503004, step = 401 (2308.209 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 468 into F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:37:51.994027 15268 basic_session_run_hooks.py:594] Saving checkpoints for 468 into F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.12777634.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:06.528198 15268 estimator.py:359] Loss for final step: 0.12777634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  3:03:53.472833\n"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:09.039033 15268 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:12.089213 15268 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:20.380266 15268 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-15T14:38:20Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:20.401237 15268 evaluation.py:257] Starting evaluation at 2019-04-15T14:38:20Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:21.692245 15268 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0415 22:38:21.694246 15268 deprecation.py:323] From E:\\Python\\virtualenv\\bert\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:21.698246 15268 saver.py:1270] Restoring parameters from F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:24.624265 15268 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:38:24.878267 15268 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-15-14:59:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:59:12.370770 15268 evaluation.py:277] Finished evaluation at 2019-04-15-14:59:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 468: auc = 0.87043816, eval_accuracy = 0.8704, f1_score = 0.87183535, false_negatives = 289.0, false_positives = 359.0, global_step = 468, loss = 0.5175862, precision = 0.85992974, recall = 0.8840754, true_negatives = 2148.0, true_positives = 2204.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:59:12.372771 15268 estimator.py:1979] Saving dict for global step 468: auc = 0.87043816, eval_accuracy = 0.8704, f1_score = 0.87183535, false_negatives = 289.0, false_positives = 359.0, global_step = 468, loss = 0.5175862, precision = 0.85992974, recall = 0.8840754, true_negatives = 2148.0, true_positives = 2204.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 468: F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0415 22:59:15.285777 15268 estimator.py:2039] Saving 'checkpoint_path' summary for global step 468: F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.87043816,\n",
       " 'eval_accuracy': 0.8704,\n",
       " 'f1_score': 0.87183535,\n",
       " 'false_negatives': 289.0,\n",
       " 'false_positives': 359.0,\n",
       " 'loss': 0.5175862,\n",
       " 'precision': 0.85992974,\n",
       " 'recall': 0.8840754,\n",
       " 'true_negatives': 2148.0,\n",
       " 'true_positives': 2204.0,\n",
       " 'global_step': 468}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "    labels = [\"Negative\", \"Positive\"]\n",
    "    input_examples = [\n",
    "        run_classifier.InputExample(guid=\"\", text_a=x, text_b=None, label=0)\n",
    "        for x in in_sentences\n",
    "    ]  # here, \"\" is just a dummy label\n",
    "    input_features = run_classifier.convert_examples_to_features(\n",
    "        input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(\n",
    "        features=input_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    return [(sentence, prediction['probabilities'],\n",
    "             labels[prediction['labels']])\n",
    "            for sentence, prediction in zip(in_sentences, predictions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = [\n",
    "  \"That movie was absolutely awful\",\n",
    "  \"The acting was a bit lacking\",\n",
    "  \"The film was creative and surprising\",\n",
    "  \"Absolutely fantastic!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.124437 15268 run_classifier.py:774] Writing example 0 of 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.125407 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.127410 15268 run_classifier.py:462] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] that movie was absolutely awful [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.128413 15268 run_classifier.py:464] tokens: [CLS] that movie was absolutely awful [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2008 3185 2001 7078 9643 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.129411 15268 run_classifier.py:465] input_ids: 101 2008 3185 2001 7078 9643 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.130410 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.131410 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.133409 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.134407 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.136422 15268 run_classifier.py:462] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the acting was a bit lacking [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.138408 15268 run_classifier.py:464] tokens: [CLS] the acting was a bit lacking [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 3772 2001 1037 2978 11158 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.139410 15268 run_classifier.py:465] input_ids: 101 1996 3772 2001 1037 2978 11158 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.140408 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.141408 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.144417 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.145408 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.146409 15268 run_classifier.py:462] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the film was creative and surprising [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.148409 15268 run_classifier.py:464] tokens: [CLS] the film was creative and surprising [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 2143 2001 5541 1998 11341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.150426 15268 run_classifier.py:465] input_ids: 101 1996 2143 2001 5541 1998 11341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.151409 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.153409 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.154407 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.155409 15268 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.157407 15268 run_classifier.py:462] guid: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] absolutely fantastic ! [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.158408 15268 run_classifier.py:464] tokens: [CLS] absolutely fantastic ! [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7078 10392 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.159407 15268 run_classifier.py:465] input_ids: 101 7078 10392 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.161407 15268 run_classifier.py:466] input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.162408 15268 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.163408 15268 run_classifier.py:468] label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:42.196410 15268 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:45.699460 15268 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:45.853446 15268 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:46.366434 15268 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:46.371434 15268 saver.py:1270] Restoring parameters from F:\\testDemo\\AI\\NER\\ChineseNER-based-BERT\\model.ckpt-468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:47.429471 15268 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0416 16:02:47.529442 15268 session_manager.py:493] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = getPrediction(pred_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That movie was absolutely awful',\n",
       "  array([-1.8512745e-03, -6.2928047e+00], dtype=float32),\n",
       "  'Negative'),\n",
       " ('The acting was a bit lacking',\n",
       "  array([-2.1979478e-03, -6.1213036e+00], dtype=float32),\n",
       "  'Negative'),\n",
       " ('The film was creative and surprising',\n",
       "  array([-5.5807433e+00, -3.7769189e-03], dtype=float32),\n",
       "  'Positive'),\n",
       " ('Absolutely fantastic!',\n",
       "  array([-5.6152534e+00, -3.6485312e-03], dtype=float32),\n",
       "  'Positive')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
